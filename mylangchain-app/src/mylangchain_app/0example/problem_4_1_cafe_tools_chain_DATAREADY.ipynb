{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f38f0ee",
   "metadata": {},
   "source": [
    "\n",
    "# 문제 4-1 : 카페 메뉴 도구"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cde0fe8",
   "metadata": {},
   "source": [
    "## 0) 환경 점검"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70d3b7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]\n",
      "Platform: Windows-11-10.0.26100-SP0\n",
      "OPENAI_API_KEY set: True\n",
      "TAVILY_API_KEY set: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, sys, platform\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"OPENAI_API_KEY set:\", bool(os.getenv(\"OPENAI_API_KEY\")))\n",
    "print(\"TAVILY_API_KEY set:\", bool(os.getenv(\"TAVILY_API_KEY\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6de6fd",
   "metadata": {},
   "source": [
    "## 1) 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33faf714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 경로: c:\\mylangchain\\mylangchain-app\\src\\mylangchain_app\\0example\\data\\cafe_menu_data.txt\n",
      "\n",
      "=== 미리보기 ===\n",
      " 1. 아메리카노\n",
      "   • 가격: ₩4,500\n",
      "   • 주요 원료: 에스프레소, 뜨거운 물\n",
      "   • 설명: 진한 에스프레소에 뜨거운 물을 더해 만든 클래식한 블랙 커피입니다. 원두 본연의 맛을 가장 잘 느낄 수 있으며, 깔끔하고 깊은 풍미가 특징입니다. 설탕이나 시럽 추가 가능합니다.\n",
      "\n",
      "2. 카페라떼\n",
      "   • 가격: ₩5,500\n",
      "   • 주요 원료: 에스프레소, 스팀 밀크\n",
      "   • 설명: 진한 에스프레소에 부드럽게 스팀한 우유를 넣어 만든 대표적인 밀크 커피입니다. 크리미한 질감과 부드러운 맛이 특징이며, 다양한 시럽과 토핑 추가가 가능합니다. 라떼 아트로 시각적 즐거움도 제공합니다.\n",
      "\n",
      "3. 카푸치노\n",
      "   • 가격: ₩5,000\n",
      "   • 주요 원료: 에스프레소, 스팀 밀크, 우유 거품\n",
      "   • 설명: 에스프레소, 스팀 밀크, 우유 거품이 1:1:1 비율로 구성된 이탈리아 전통 커피입니다. 진한 커피 맛과 부드러운 우유 거품의 조화가 일품이며, 계피 파우더를 뿌려 제공합니다.\n",
      "\n",
      "4. 바 ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path.cwd() / \"data\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "menu_path = DATA_DIR / \"cafe_menu_data.txt\"\n",
    "\n",
    "assert menu_path.exists(), f\"파일이 없습니다: {menu_path}\"\n",
    "txt = menu_path.read_text(encoding=\"utf-8\")\n",
    "print(\"파일 경로:\", menu_path)\n",
    "print(\"\\n=== 미리보기 ===\\n\", txt[:500], \"...\" if len(txt)>500 else \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a7cedf",
   "metadata": {},
   "source": [
    "## 2) 벡터 DB 구축 (FAISS, OpenAI Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "763267a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mylangchain-app-SBe-Yh6W-py3.12\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 문서 블록 수: 10\n",
      "✅ FAISS index saved to: c:\\mylangchain\\mylangchain-app\\src\\mylangchain_app\\0example\\db\\cafe_db\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re, json\n",
    "from pathlib import Path\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "DB_DIR = Path.cwd() / \"db\" / \"cafe_db\"\n",
    "DB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- 문서 분할 ---\n",
    "# 기본 포맷 가정: 메뉴 블록 간 빈 줄로 구분, 각 블록 첫 줄=메뉴명\n",
    "blocks = [b.strip() for b in re.split(r\"\\n\\s*\\n\", txt) if b.strip()]\n",
    "\n",
    "docs = []\n",
    "for block in blocks:\n",
    "    lines = block.splitlines()\n",
    "    menu_name = lines[0].strip() if lines else \"Unknown\"\n",
    "    docs.append(Document(page_content=block, metadata={\"menu_name\": menu_name}))\n",
    "\n",
    "print(f\"총 문서 블록 수: {len(docs)}\")\n",
    "\n",
    "# --- 임베딩 & 인덱스 ---\n",
    "emb = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vs = FAISS.from_documents(docs, emb)\n",
    "vs.save_local(str(DB_DIR))\n",
    "print(\"✅ FAISS index saved to:\", DB_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e341968",
   "metadata": {},
   "source": [
    "## 3) 도구 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29c5d3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json, wikipedia\n",
    "from langchain.tools import tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pathlib import Path\n",
    "\n",
    "DB_DIR = Path.cwd() / \"db\" / \"cafe_db\"\n",
    "emb = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "@tool(\"tavily_search_func\", return_direct=False)\n",
    "def tavily_search_func(query: str) -> str:\n",
    "    \"\"\"웹에서 최신 정보를 검색합니다 (Tavily). 입력: 검색어(str). 출력: 요약 문자열.\"\"\"\n",
    "    tavily = TavilySearchResults(max_results=5)\n",
    "    results = tavily.invoke({\"query\": query})\n",
    "    out = []\n",
    "    for i, r in enumerate(results, 1):\n",
    "        out.append(f\"[{i}] {r.get('url','')}\\n{r.get('content','')[:300]}...\")\n",
    "    return \"\\n\\n\".join(out) if out else \"검색 결과가 없습니다.\"\n",
    "\n",
    "@tool(\"wiki_summary\", return_direct=False)\n",
    "def wiki_summary(topic: str) -> str:\n",
    "    \"\"\"위키피디아에서 주제 요약을 제공합니다. 입력: 주제(str). 출력: 요약 문자열.\"\"\"\n",
    "    try:\n",
    "        wikipedia.set_lang(\"ko\")\n",
    "        return wikipedia.summary(topic, sentences=3, auto_suggest=False, redirect=True)\n",
    "    except Exception as e:\n",
    "        return f\"위키 요약 실패: {e}\"\n",
    "\n",
    "@tool(\"db_search_cafe_func\", return_direct=False)\n",
    "def db_search_cafe_func(query: str) -> str:\n",
    "    \"\"\"로컬 카페 메뉴 DB에서 유사한 항목을 검색합니다. 입력: 쿼리(str). 출력: JSON 문자열(List[Document]).\"\"\"\n",
    "    local_vs = FAISS.load_local(str(DB_DIR), embeddings=emb, allow_dangerous_deserialization=True)\n",
    "    found = local_vs.similarity_search(query, k=4)\n",
    "    payload = [{\"page_content\": d.page_content, \"metadata\": d.metadata} for d in found]\n",
    "    return json.dumps(payload, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ef89ac",
   "metadata": {},
   "source": [
    "## 4) LLM 바인딩 및 @chain 워크플로우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "149ade67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict, Any\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "TOOLS = [tavily_search_func, wiki_summary, db_search_cafe_func]\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(TOOLS)\n",
    "\n",
    "@chain\n",
    "def cafe_tool_chain(question: str) -> Dict[str, Any]:\n",
    "    ai: AIMessage = llm_with_tools.invoke(question)\n",
    "    calls = getattr(ai, \"tool_calls\", []) or []\n",
    "    tool_results = []\n",
    "\n",
    "    if calls:\n",
    "        for c in calls:\n",
    "            name = c[\"name\"]\n",
    "            args = c.get(\"args\", {})\n",
    "            if name == \"tavily_search_func\":\n",
    "                out = tavily_search_func.invoke(args.get(\"query\", question))\n",
    "            elif name == \"wiki_summary\":\n",
    "                out = wiki_summary.invoke(args.get(\"topic\", question))\n",
    "            elif name == \"db_search_cafe_func\":\n",
    "                out = db_search_cafe_func.invoke(args.get(\"query\", question))\n",
    "            else:\n",
    "                out = f\"알 수 없는 도구: {name}\"\n",
    "            tool_results.append({\"tool\": name, \"output\": out})\n",
    "\n",
    "        ctx = \"\\n\\n\".join([f\"[{r['tool']}]\\n{r['output']}\" for r in tool_results])\n",
    "        final = llm.invoke(f\"\"\"사용자 질문: {question}\n",
    "아래 도구 결과를 참고하여 한국어로 간결하고 정확하게 답하세요.\n",
    "\n",
    "도구 결과:\n",
    "{ctx}\n",
    "\"\"\")\n",
    "        return {\"answer\": final.content, \"tool_calls\": calls, \"tool_results\": tool_results}\n",
    "    else:\n",
    "        return {\"answer\": ai.content, \"tool_calls\": [], \"tool_results\": []}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ba841c",
   "metadata": {},
   "source": [
    "## 5) 테스트 — “아메리카노의 가격과 특징은 무엇인가요?”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf69bd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mylangchain-app-SBe-Yh6W-py3.12\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mylangchain-app-SBe-Yh6W-py3.12\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 최종 답변 ===\n",
      " 아메리카노의 가격은 ₩4,500입니다. 주요 원료는 에스프레소와 뜨거운 물로, 진한 에스프레소에 뜨거운 물을 더해 만든 클래식한 블랙 커피입니다. 원두 본연의 맛을 잘 느낄 수 있으며, 깔끔하고 깊은 풍미가 특징입니다. 설탕이나 시럽을 추가할 수 있습니다.\n",
      "\n",
      "=== 도구 호출 내역 ===\n",
      " [{'name': 'db_search_cafe_func', 'args': {'query': '아메리카노'}, 'id': 'call_MLEsEkIcg5qI2sgwCFmTqjU2', 'type': 'tool_call'}, {'name': 'wiki_summary', 'args': {'topic': 'Americano'}, 'id': 'call_qrkJLlxZAlGw6ZsEIQAJ1xts', 'type': 'tool_call'}]\n",
      "\n",
      "=== 도구 실행 결과(요약) ===\n",
      "- db_search_cafe_func: [{\"page_content\": \"1. 아메리카노\\n   • 가격: ₩4,500\\n   • 주요 원료: 에스프레소, 뜨거운 물\\n   • 설명: 진한 에스프레소에 뜨거운 물을 더해 만든 클래식한 블랙 커피입니다. 원두 본연의 맛을 가장 잘 느낄 수 있으며, 깔끔하고 깊은 풍미가 특징입니다. 설탕이나 시럽 추가 가능합니다....\n",
      "- wiki_summary: 위키 요약 실패: \"아메리카노\" may refer to: \n",
      "카페 아메리카노\n",
      "아메리카노\n",
      "10cm\n",
      "Americano (노래)\n",
      "사비에르 쿠가트\n",
      "아메리카노 (2005년 영화)\n",
      "아메리카노 (2011년 영화)\n",
      "아메리카누 FC\n",
      "제목에 \"아메리카노\" 항목을 포함한 모든 문서\n",
      "아메리카나\n",
      "아메리칸...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "out = cafe_tool_chain.invoke(\"아메리카노의 가격과 특징은 무엇인가요?\")\n",
    "print(\"=== 최종 답변 ===\\n\", out[\"answer\"])\n",
    "print(\"\\n=== 도구 호출 내역 ===\\n\", out[\"tool_calls\"])\n",
    "print(\"\\n=== 도구 실행 결과(요약) ===\")\n",
    "for r in out[\"tool_results\"]:\n",
    "    print(f\"- {r['tool']}: {str(r['output'])[:180]}...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
