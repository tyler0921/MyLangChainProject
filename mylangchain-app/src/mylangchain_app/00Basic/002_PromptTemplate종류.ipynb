{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate \n",
    "* [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html#langchain_core.prompts.prompt.PromptTemplate)\n",
    "* [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#langchain_core.prompts.chat.ChatPromptTemplate)\n",
    "* [ChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatMessagePromptTemplate.html#langchain_core.prompts.chat.ChatMessagePromptTemplate)\n",
    "* [FewShotPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html#langchain_core.prompts.few_shot.FewShotPromptTemplate)\n",
    "* PartialPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_Z\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) PromptTemplate ì˜ from_template() í•¨ìˆ˜ ì‚¬ìš©\n",
    "* ì£¼ë¡œ LLM(í…ìŠ¤íŠ¸ ì™„ì„±í˜• ëª¨ë¸, ex. Ollama, GPT-3.5)ê³¼ í•¨ê»˜ ì‚¬ìš©\n",
    "* í•˜ë‚˜ì˜ ë¬¸ìì—´ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ChatGPTëŠ” ì¸í„°ë„·ì˜ ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ì—ì„œ ë‹¨ì–´ì™€ ë¬¸ì¥ì˜ ì¶œí˜„ íŒ¨í„´ì„ í•™ìŠµí•´, ë‹¤ìŒì— ì˜¬ ê°€ëŠ¥ì„±ì´ ë†’ì€ í† í°ì„ í™•ë¥ ì ìœ¼ë¡œ '\n",
      " 'ì˜ˆì¸¡í•©ë‹ˆë‹¤.  \\n'\n",
      " 'í•™ìŠµ ê³¼ì •ì—ì„œ ì¸ê°„ì˜ í”¼ë“œë°±(RLHF)ì„ í†µí•´ ìœ í•´í•˜ê±°ë‚˜ ë¶€ì •í™•í•œ ë‹µë³€ì„ ì¤„ì´ê³ , ì‚¬ìš©ìì˜ ì„ í˜¸ì— ë§ëŠ” ëŒ€í™” ìŠ¤íƒ€ì¼ì„ ê°•í™”í•©ë‹ˆë‹¤.  \\n'\n",
      " 'ê²°êµ­ í†µê³„ì  íŒ¨í„´ ë§¤ì¹­ê³¼ ë³´ìƒ ìµœì í™”ë¥¼ í†µí•´ â€œë¬¸ë§¥ì— ë§ëŠ” ë§â€ì„ ë§Œë“¤ì–´ë‚´ëŠ”, ë§í•˜ìë©´ â€œí™•ë¥  ê¸°ë°˜ì˜ ìë™ì™„ì„± ê¸°ê³„â€ì…ë‹ˆë‹¤.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pprint import pprint\n",
    "\n",
    "template_text = \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# PromptTemplate ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "    #model=\"openai/gpt-oss-120b\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3})\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) PromptTemplate ê²°í•©í•˜ê¸°\n",
    "* ë™ì¼í•œ Prompt íŒ¨í„´ì„ ì‚¬ìš©í•˜ì§€ë§Œ ì—¬ëŸ¬ ê°œì˜ ì§ˆë¬¸ì„ ì‘ì„±í•´ì„œ LLMì„ ì‹¤í–‰í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['count', 'language', 'model_name'] input_types={} partial_variables={} template='{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\\n\\n ê·¸ë¦¬ê³  {model_name} ëª¨ë¸ì˜ ì¥ì ì„ ìš”ì•½ ì •ë¦¬í•´ ì£¼ì„¸ìš”\\n\\n {model_name} ëª¨ë¸ê³¼ ë¹„ìŠ·í•œ AI ëª¨ë¸ì€ ì–´ë–¤ ê²ƒì´ ìˆë‚˜ìš”? ëª¨ë¸ëª…ì€ {language}ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.'\n",
      "('1. ChatGPTëŠ” ì¸í„°ë„·ì˜ ë°©ëŒ€í•œ ê¸€ì„ ë¯¸ë¦¬ í•™ìŠµí•´ â€œë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ”â€ ë°©ì‹ìœ¼ë¡œ, ì‚¬ëŒì´ ì“´ ê¸€ì˜ íŒ¨í„´ì„ ìˆ«ìë¡œ '\n",
      " 'ê¸°ì–µí•©ë‹ˆë‹¤.  \\n'\n",
      " '2. ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ë˜ì§€ë©´, ê·¸ ì§ˆë¬¸ì„ ìˆ«ìë¡œ ë°”ê¿” ê¸°ì–µ ì† íŒ¨í„´ê³¼ ë¹„êµí•´ ê°€ì¥ ì ì ˆí•œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.  \\n'\n",
      " '3. ì´ ê³¼ì •ì—ì„œ ì‚¬ëŒì˜ í”¼ë“œë°±(ê°•í™”í•™ìŠµ)ì„ ë°›ì•„ ê±°ì§“Â·í¸í–¥Â·ë¬´ë¡€í•œ ë‹µë³€ì„ ì¤„ì´ê³ , ìœ ìš©í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ë§Œë“¤ë„ë¡ ë¯¸ì„¸ '\n",
      " 'ì¡°ì •ë©ë‹ˆë‹¤.\\n'\n",
      " '\\n'\n",
      " 'ChatGPT ëª¨ë¸ì˜ ì£¼ìš” ì¥ì  ìš”ì•½  \\n'\n",
      " 'â€¢ ë§¥ë½ ì´í•´ ëŠ¥ë ¥: ê¸´ ëŒ€í™”ë‚˜ ê¸€ì„ ì½ê³  íë¦„ì„ ê¸°ì–µí•´ ë…¼ë¦¬ì ì´ê³  ì¼ê´€ëœ ë‹µë³€ ìƒì„±  \\n'\n",
      " 'â€¢ ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ ì§€ì›: ì„¤ëª…Â·ìš”ì•½Â·ì°½ì‘Â·ì½”ë“œ ì‘ì„± ë“± ì§§ì€ ì§€ì‹œì–´ë§Œìœ¼ë¡œë„ ì›í•˜ëŠ” í˜•ì‹Â·í†¤ìœ¼ë¡œ ì¶œë ¥  \\n'\n",
      " 'â€¢ ì¦‰ì‹œ í™œìš© ê°€ëŠ¥: ë³„ë„ ì¬í•™ìŠµ ì—†ì´ ì¦‰ì„ì—ì„œ ìƒˆë¡œìš´ ì£¼ì†Œ, ì–¸ì–´, ë¶„ì•¼ì— ëŒ€ì‘í•´ ì‹¤ìš©ì  ë‹µë³€ ì œê³µ  \\n'\n",
      " 'â€¢ ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜: RLHFë¡œ ê±°ì§“Â·ìœ í•´ ë‹µë³€ì„ ì¤„ì—¬ ì‹ ë¢°ë„Â·ì•ˆì „ì„± í–¥ìƒ  \\n'\n",
      " 'â€¢ ë‹¤êµ­ì–´Â·ë©€í‹°ëª¨ë‹¬ ì§€ì›: í•œêµ­ì–´ë¥¼ í¬í•¨í•œ 50ì—¬ ê°œ ì–¸ì–´, ì´ë¯¸ì§€Â·ìŒì„± ì…ë ¥ê¹Œì§€ ì²˜ë¦¬ ê°€ëŠ¥(ë²„ì „ì— ë”°ë¼)  \\n'\n",
      " 'â€¢ í™•ì¥ç”Ÿíƒœê³„: í”ŒëŸ¬ê·¸ì¸Â·APIÂ·íŒŒì¸íŠœë‹ ê¸°ëŠ¥ìœ¼ë¡œ ê³ ê° ì„œë¹„ìŠ¤, êµìœ¡, ì½”ë”© ë³´ì¡° ë“± ì‚°ì—… ì „ë°˜ì— ì‰½ê²Œ í†µí•©\\n'\n",
      " '\\n'\n",
      " 'ChatGPTì™€ ë¹„ìŠ·í•œ AI ëª¨ë¸  \\n'\n",
      " 'â€¢ êµ¬ê¸€ ì œë¯¸ë‚˜ì´(Gemini)  \\n'\n",
      " 'â€¢ ë©”íƒ€ ëšœê»‘ì—´ê¸°(Llama)  \\n'\n",
      " 'â€¢ ì•ˆíŠ¸ë¡œí”½ í´ë ˆë“œ(Claude)  \\n'\n",
      " 'â€¢ 01.AI ì™€ì´ì½”(WizardLM)  \\n'\n",
      " 'â€¢ ì•Œë¦¬ë°”ë‹¤ íì›¬(Qwen)  \\n'\n",
      " 'â€¢ ì—…ìŠ¤íŠ¸ëŸ´ ë¨¸ë ›(Mistral)')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# PromptTemplate ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# í…œí”Œë¦¿ì— ê°’ì„ ì±„ì›Œì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ì™„ì„±\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# ë¬¸ìì—´ í…œí”Œë¦¿ ê²°í•© (PromptTemplate + PromptTemplate + ë¬¸ìì—´)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n ê·¸ë¦¬ê³  {model_name} ëª¨ë¸ì˜ ì¥ì ì„ ìš”ì•½ ì •ë¦¬í•´ ì£¼ì„¸ìš”\")\n",
    "              + \"\\n\\n {model_name} ëª¨ë¸ê³¼ ë¹„ìŠ·í•œ AI ëª¨ë¸ì€ ì–´ë–¤ ê²ƒì´ ìˆë‚˜ìš”? ëª¨ë¸ëª…ì€ {language}ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"í•œêµ­ì–´\")\n",
    "print(combined_prompt)\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"í•œêµ­ì–´\"})\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PromptTemplate ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ë°°ì—´ í˜•íƒœë¡œ í•˜ì—¬ ì—¬ëŸ¬ê°œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 3 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.', 'Gemini ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 4 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.', 'claude ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 4 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.']\n",
      "<class 'str'> GPT-4 ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 3 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n",
      "('GPT-4ëŠ” ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¨ì–´Â·êµ¬ë¬¸ ê°„ í™•ë¥  ê´€ê³„ë¥¼ í•™ìŠµí•´, ì£¼ì–´ì§„ ì•ë‹¨ì–´ë“¤ ë‹¤ìŒì— ì˜¬ ìµœì ì˜ í† í°ì„ ì˜ˆì¸¡í•˜ëŠ” '\n",
      " 'ë°©ì‹ìœ¼ë¡œ í›ˆë ¨ë©ë‹ˆë‹¤.  \\n'\n",
      " 'í•™ìŠµ ê³¼ì •ì—ì„œ ì¸ê°„ í‰ê°€ìì˜ ì„ í˜¸ë„ë¥¼ ë°˜ì˜í•œ ê°•í™”í•™ìŠµ ê¸°ë²•(RLHF)ì´ ì¶”ê°€ë¡œ ì ìš©ë˜ì–´, ìœ ìš©í•˜ê³  ì•ˆì „í•œ ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ ë¯¸ì„¸ '\n",
      " 'ì¡°ì •ë©ë‹ˆë‹¤.  \\n'\n",
      " 'ì´ë ‡ê²Œ í•™ìŠµëœ ëŒ€ê·œëª¨ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì€ ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ì „ì— ë³¸ ì  ì—†ëŠ” ìƒˆë¡œìš´ ë¬¸ì¥ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì—°ê²°í•´ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤.')\n",
      "<class 'str'> Gemini ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 4 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n",
      "('GeminiëŠ” í…ìŠ¤íŠ¸Â·ì´ë¯¸ì§€Â·ì˜¤ë””ì˜¤Â·ì½”ë“œ ë“± ë‹¤ì–‘í•œ ë°ì´í„°ë¥¼ í•œêº¼ë²ˆì— ë°›ì•„ë“¤ì´ëŠ” ë©€í‹°ëª¨ë‹¬ ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°ì— '\n",
      " 'ì „ë¬¸ê°€ í˜¼í•©(MoE) ë°©ì‹ì„ ë”í•´ í¬ì†Œ í™œì„±í™”ë¡œ íš¨ìœ¨ì„ ë†’ì¸ë‹¤.  \\n'\n",
      " 'í•™ìŠµ ì´ˆê¸°ì—” ë‹¤ìŒ í† í° ì˜ˆì¸¡ê³¼ ëŒ€ê·œëª¨ ëŒ€ë¹„í•™ìŠµìœ¼ë¡œ ì¼ë°˜ ì§€ì‹ì„ ìµíˆê³ , ì´í›„ ì§€ì‹œ ë”°ë¥´ê¸°Â·ì¸ê°„ í”¼ë“œë°± ê°•í™”í•™ìŠµ(RLHF)ì„ í†µí•´ ì‚¬ëŒì˜ '\n",
      " 'ì„ í˜¸ë„ì— ë§ì¶˜ ì •ë ¬ì„ ìˆ˜í–‰í•œë‹¤.  \\n'\n",
      " 'ì²´ì¸-of-thought í”„ë¡¬í”„íŠ¸ì™€ ì •ì±… ìµœì í™” ê¸°ë²•ì„ ë°˜ë³µí•´ ì¶”ë¡  ê²½ë¡œë¥¼ í™•ì¥Â·ì„¸ë°€í•˜ê²Œ ë§Œë“¤ì–´ ìˆ˜í•™Â·ì½”ë”© ë“± ë³µì¡í•œ ë¬¸ì œë¥¼ ë‹¨ê³„ì ìœ¼ë¡œ '\n",
      " 'í•´ê²°í•˜ë„ë¡ í›ˆë ¨í•œë‹¤.  \\n'\n",
      " 'ëª¨ë¸ í¬ê¸°ì— ë”°ë¼ NanoÂ·ProÂ·Ultra ë“± ì—¬ëŸ¬ ë²„ì „ìœ¼ë¡œ ë°°í¬í•´, ì¼ì • ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì€ ìœ ì§€í•˜ë©´ì„œ ê³„ì‚° ë¹„ìš©ê³¼ ì¶”ë¡  ì†ë„ë¥¼ ê· í˜• ìˆê²Œ '\n",
      " 'ì¡°ì ˆí•œë‹¤.')\n",
      "<class 'str'> claude ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 4 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n",
      "('ClaudeëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ë¡œ, ì¸í„°ë„·ì˜ ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ë¥¼ í†µí•´ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ ì‚¬ì „í•™ìŠµë©ë‹ˆë‹¤.  \\n'\n",
      " 'ì´í›„ ì¸ê°„ íŠœë„ˆê°€ ëŒ€í™” í’ˆì§ˆ, ë„ì›€ì„±, ë¬´í•´ì„± ë“±ì„ ê¸°ì¤€ìœ¼ë¡œ ì‘ë‹µì„ ìˆœìœ„ ë§¤ê²¨ ì£¼ë©´, ì´ë¥¼ ë³´ìƒìœ¼ë¡œ ì‚¼ì•„ ê°•í™”í•™ìŠµìœ¼ë¡œ '\n",
      " 'ë¯¸ì„¸ì¡°ì •ë©ë‹ˆë‹¤.  \\n'\n",
      " 'ì´ ê³¼ì •ì—ì„œæ†²æ³•(í—Œë²•)ì´ë¼ëŠ” ì›ì¹™ ë¬¸ì„œë¥¼ í†µí•´ ìœ¤ë¦¬ì  ê¸°ì¤€ì„ ì§€ì†ì ìœ¼ë¡œ ê°•í™”í•˜ë©°, ìœ í•´í•˜ê±°ë‚˜ ì˜ëª»ëœ ë‹µë³€ ìƒì„±ì„ ì–µì œí•©ë‹ˆë‹¤.  \\n'\n",
      " 'ê²°êµ­ ëŒ€í™” ë§¥ë½ì„ Transformer ì•„í‚¤í…ì²˜ë¡œ ì¸ì½”ë”©í•œ ë’¤, í™•ë¥  ë¶„í¬ë¥¼ ê³„ì‚°í•´ ê°€ì¥ ì ì ˆí•œ í† í°ì„ ìˆœì°¨ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# PromptTemplate ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 3},\n",
    "    {\"model_name\": \"Gemini\", \"count\": 4},\n",
    "    {\"model_name\": \"claude\", \"count\": 4},\n",
    "]\n",
    "\n",
    "# ì—¬ëŸ¬ ê°œì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë¯¸ë¦¬ ìƒì„±\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # ë¯¸ë¦¬ ìƒì„±ëœ ì§ˆë¬¸ ëª©ë¡ í™•ì¸\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    print(type(prompt), prompt)\n",
    "    response = llm.invoke(prompt)\n",
    "    pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) ChatPromptTemplate\n",
    "* Tuple í˜•íƒœì˜ system, user, assistant ë©”ì‹œì§€ ì§€ì›\n",
    "* ì—¬ëŸ¬ ê°œì˜ ë©”ì‹œì§€ë¥¼ ì¡°í•©í•˜ì—¬ LLMì—ê²Œ ì „ë‹¬ ê°€ëŠ¥\n",
    "* ê°„ê²°ì„±ê³¼ ê°€ë…ì„±ì´ ë†’ê³  ë‹¨ìˆœí•œ êµ¬ì¡°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='This system is an expert in answering questions about AI.      Please provide clear and detailed explanations.', additional_kwargs={}, response_metadata={}), HumanMessage(content='ChatGPT ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”.', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "ChatGPTëŠ” â€œì–´ë–»ê²Œ ê³µë¶€í•˜ëŠ”ê°€?â€ë³´ë‹¤ â€œì–´ë–»ê²Œ â€˜ê³µë¶€í•œ ê²ƒâ€™ì„ í™œìš©í•˜ëŠ”ê°€?â€ì— ì´ˆì ì´ ë§ì¶°ì§„ ëª¨ë¸ì…ë‹ˆë‹¤.  \n",
      "ìš”ì»¨ëŒ€, **â€˜ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ë¥¼ ë°˜ë³µí•´ ì½ìœ¼ë©° ë‹¤ìŒ ë‹¨ì–´ë¥¼ ë§íˆëŠ” ë†€ì´â€™ë¥¼ ì—„ì²­ë‚œ ì–‘ìœ¼ë¡œ í•˜ì—¬, ê·¸ ê³¼ì •ì—ì„œ ì–¸ì–´ì˜ íŒ¨í„´ì„ ì•”ê¸°í•œ ë’¤, ì‚¬ìš©ì ì§ˆë¬¸ì— ë§ì¶° íŒ¨í„´ì„ êº¼ë‚´ ì¡°í•©í•˜ëŠ” ë°©ì‹**ì…ë‹ˆë‹¤. ì•„ë˜ì— 4ë‹¨ê³„ë¡œ ë‚˜ëˆ  ì„¤ëª…í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "----------------------------------------\n",
      "1. ì „ì²´ íë¦„ ìš”ì•½\n",
      "1) Pre-training(ì‚¬ì „í•™ìŠµ)  \n",
      "   â†’ â€œë‹¤ìŒ ë‹¨ì–´ ë§íˆê¸°â€ ë°˜ë³µìœ¼ë¡œ â€˜ì¼ë°˜ ì–¸ì–´ ëŠ¥ë ¥â€™ì„ íšë“  \n",
      "2) Supervised Fine-Tuning(SFT, ë¯¸ì„¸ì¡°ì •)  \n",
      "   â†’ ì§ˆë¬¸-ë‹µë³€ ë°ì´í„°ë¡œ â€˜ëŒ€í™” í˜•ì‹â€™ì„ ìµí˜  \n",
      "3) Reward Model(RM) í•™ìŠµ  \n",
      "   â†’ â€˜ì¢‹ì€ ë‹µâ€™ vs â€˜ë‚˜ìœ ë‹µâ€™ì„ ê°€ë¥´ì³ ì£¼ëŠ” í‰ê°€ì‚¬ë¥¼ ë§Œë“¦  \n",
      "4) PPO(ê°•í™”í•™ìŠµ) ìµœì í™”  \n",
      "   â†’ í‰ê°€ì‚¬ì˜ ì ìˆ˜ë¥¼ ë†’ì´ëŠ” ë°©í–¥ìœ¼ë¡œ ì¶”ê°€ í•™ìŠµ  \n",
      "----------------------------------------\n",
      "2. 1ë‹¨ê³„: Pre-training(ì–¸ì–´ ëª¨ë¸ ë§Œë“¤ê¸°)\n",
      "â€¢ ëª©í‘œ  \n",
      "  â€“ ì£¼ì–´ì§„ ì• ë¬¸ì¥(ì»¨í…ìŠ¤íŠ¸)ë¥¼ ë³´ê³  ë‹¤ìŒì— ë‚˜ì˜¬ í† í°(ë‹¨ì–´/ë¶€ë¶„ë‹¨ì–´)ì„ í™•ë¥ ë¡œ ì˜ˆì¸¡  \n",
      "â€¢ ë°ì´í„°  \n",
      "  â€“ ì›¹, ì±…, ë…¼ë¬¸, ìœ„í‚¤ ë“± ìˆ˜ì²œì–µ í† í°  \n",
      "â€¢ ëª¨ë¸ êµ¬ì¡°  \n",
      "  â€“ Transformer ë””ì½”ë” ë¸”ë¡ ìŒ“ê¸°  \n",
      "  â€“ Self-Attentionìœ¼ë¡œ â€˜ëª¨ë“  ë‹¨ì–´ê°€ ëª¨ë“  ë‹¨ì–´ë¥¼ ì°¸ì¡°â€™í•˜ë©° íŒ¨í„´ í¡ìˆ˜  \n",
      "â€¢ ìµœì í™”  \n",
      "  â€“ Cross-Entropy ì†ì‹¤ â†“ (ì •ë‹µ í† í°ì— ë†’ì€ í™•ë¥ )  \n",
      "  â€“ ìˆ˜ë°±~ìˆ˜ì²œ GPUë¡œ ìˆ˜ ì£¼~ìˆ˜ ê°œì›”  \n",
      "â€¢ ê²°ê³¼  \n",
      "  â€“ â€œê³µë¶€í•œ ì§€ì‹â€ì€ í™•ë¥  ë¶„í¬ë¡œ ì••ì¶•ë˜ì–´ ê°€ì¤‘ì¹˜(Weight)ì— ì €ì¥ë¨  \n",
      "  â€“ ì§ˆë¬¸ì— ëŒ€í•œ í™•ë¥  ê³„ì‚°ì´ ê°€ëŠ¥í•´ì§(P(ë‹µ|ì§ˆë¬¸))\n",
      "\n",
      "----------------------------------------\n",
      "3. 2ë‹¨ê³„: Supervised Fine-Tuning(SFT)\n",
      "â€¢ ë¬¸ì œ  \n",
      "  â€“ Pre-trained ëª¨ë¸ì€ â€˜ìë™ì™„ì„±â€™ë§Œ ì˜ í•  ë¿, â€˜ëŒ€í™”â€™ëŠ” ì„œíˆ¼  \n",
      "â€¢ í•´ê²°  \n",
      "  â€“ ì‚¬ëŒì´ ì‘ì„±í•œ (í”„ë¡¬í”„íŠ¸, ì´ìƒì  ë‹µë³€) ìŒ â‰ˆ10ë§Œ ê°œë¡œ ì¶”ê°€í•™ìŠµ  \n",
      "â€¢ íš¨ê³¼  \n",
      "  â€“ â€œëŒ€í™” ê·œì¹™, ì¸ì‚¬, ê±°ì ˆ, ìš”ì•½â€ ë“± í˜•ì‹ì  ë§¤ë„ˆë¥¼ ê¸ˆë°© ìµí˜  \n",
      "  â€“ ì¼ë°˜ ì§€ì‹ì€ Pre-training ëª«, í˜•ì‹ì€ SFT ëª«ìœ¼ë¡œ ë¶„ë¦¬\n",
      "\n",
      "----------------------------------------\n",
      "4. 3ë‹¨ê³„: Reward Model ë§Œë“¤ê¸°\n",
      "â€¢ í•„ìš”ì„±  \n",
      "  â€“ â€˜ì˜¬ë°”ë¥¸ ë‹µâ€™ì„ ë‹¨ìˆœíˆ ëª¨ë°©ë§Œìœ¼ë¡œëŠ” ë¯¸ë¬˜í•œ í’ˆì§ˆ ì°¨ì´ë¥¼ ë°˜ì˜ ëª» í•¨  \n",
      "â€¢ ë°©ë²•  \n",
      "  â€“ ê°™ì€ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ ëª¨ë¸ì´ ë§Œë“  4~9ê°œ ë‹µë³€ì„ ì‚¬ëŒì´ 1â†’5 ì ìœ¼ë¡œ ë¹„êµ  \n",
      "  â€“ ì´ ë¹„êµ ë°ì´í„°ë¡œ ë³„ë„ì˜ Reward Model(RM)ì„ í•™ìŠµ  \n",
      "  â€“ RMì€ ì…ë ¥(í”„ë¡¬í”„íŠ¸+ë‹µë³€) â†’ scalar ì ìˆ˜ë¥¼ ë‚´ë±‰ìŒ\n",
      "\n",
      "----------------------------------------\n",
      "5. 4ë‹¨ê³„: PPO(ê°•í™”í•™ìŠµ)ë¡œ ì ìˆ˜ ê·¹ëŒ€í™”\n",
      "â€¢ ì•Œê³ ë¦¬ì¦˜  \n",
      "  â€“ Proximal Policy Optimization(PPO)  \n",
      "â€¢ ëª©í‘œ  \n",
      "  â€“ Ï€Î¸(ì •ì±…)ì˜ ë‹µë³€ì— ëŒ€í•´ RMì´ ì£¼ëŠ” ë³´ìƒ rì„ ê·¹ëŒ€í™”  \n",
      "  â€“ ë™ì‹œì— KL-penalty(Ï€Î¸â€–Ï€SFT)ë¡œ â€˜ì›ë³¸ ëª¨ë¸ê³¼ ë„ˆë¬´ ë©€ì–´ì§€ì§€ ì•Šê¸°â€™ ì œì•½  \n",
      "â€¢ ë°˜ë³µ  \n",
      "  â€“ Rollout(ë‹µ ìƒì„±) â†’ RM í‰ê°€ â†’ ì •ì±… ì—…ë°ì´íŠ¸  \n",
      "  â€“ ìˆ˜ì‹­~ìˆ˜ë°± íšŒ ë°˜ë³µ  \n",
      "â€¢ ê²°ê³¼  \n",
      "  â€“ ë„ì›€ë¨, ë¬´í•´í•¨, ê°„ê²°í•¨ ê°™ì€ â€˜ì‚¬ëŒ ì„ í˜¸â€™ íŠ¹ì„±ì´ ê°•í™”ë¨\n",
      "\n",
      "----------------------------------------\n",
      "6. ì™œ â€œì´í•´â€ê°€ ì•„ë‹ˆë¼ â€œíŒ¨í„´ ì¬ì¡°í•©â€ì¸ê°€?\n",
      "â€¢ í™•ë¥ ì  íŒ¨í„´ ë§¤í•‘ â†’ ë³¸ì§ˆì ìœ¼ë¡œ ê¸°í˜¸ ì¡°ì‘  \n",
      "â€¢ ë”°ë¼ì„œ ì‚¬ì‹¤ ì˜¤ë¥˜, ë…¼ë¦¬ ë¹„ì•½, í™˜ììƒì„± ê°€ëŠ¥  \n",
      "â€¢ â€˜í° í‹€ì˜ ì—°ê´€ì„±â€™ì€ í†µê³„ì ìœ¼ë¡œ ë†’ì§€ë§Œ, ì¸ê³¼ ì¶”ë¡ ì€ ì œí•œì \n",
      "\n",
      "----------------------------------------\n",
      "7. í•œ ì¤„ ìš”ì•½\n",
      "ChatGPTëŠ”  \n",
      "1) â€œë‹¤ìŒ ë‹¨ì–´ ë§íˆê¸°â€ë¡œ ì„¸ìƒ ê¸€ì„ ëª¨ë‘ ì½ì–´ ë‘ê³ ,  \n",
      "2) â€œì¢‹ì€ ëŒ€í™” ì˜ˆì‹œâ€ë¡œ ë§¤ë„ˆë¥¼,  \n",
      "3) â€œì‚¬ëŒì˜ ì„ í˜¸ ì ìˆ˜â€ë¡œ í’ˆì§ˆì„ ê°•í™”í•˜ì—¬  \n",
      "ì‚¬ìš©ì ì§ˆë¬¸ì— í†µê³„ì ìœ¼ë¡œ ì ì ˆí•œ â€˜ë‹¨ì–´ í™•ë¥  ë¶„í¬â€™ë¥¼ ì°ì–´ë‚´ëŠ”,  \n",
      "ê±°ëŒ€í•œ ìë™ì™„ì„± ê¸°ê³„ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# 2-íŠœí”Œ í˜•íƒœì˜ ë©”ì‹œì§€ ëª©ë¡ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„± (type, content)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    # role, message\n",
    "    (\"system\", \"This system is an expert in answering questions about {topic}. \\\n",
    "     Please provide clear and detailed explanations.\"),\n",
    "    (\"human\", \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\"),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", model_name=\"ChatGPT\")\n",
    "print(messages)\n",
    "\n",
    "# ìƒì„±í•œ ë©”ì‹œì§€ë¥¼ ë°”ë¡œ ì£¼ì…í•˜ì—¬ í˜¸ì¶œí•˜ê¸°\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(type(response))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "ChatGPTëŠ” â€˜ìƒì„±í˜• ì‚¬ì „ í•™ìŠµ íŠ¸ëœìŠ¤í¬ë¨¸â€™(Generative Pre-trained Transformer) ê³„ì—´ ëª¨ë¸ë¡œ,  \n",
      "â€œê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì´ ì–¸ì–´ë¥¼ ì–»ëŠ” ë²• = í™•ë¥ ì ìœ¼ë¡œ ë‹¤ìŒ í† í°(next token)ì„ ì˜ˆì¸¡í•˜ëŠ” ì—°ì†ì„±ì˜ í•™ìŠµâ€ì´ë¼ëŠ” ë‹¨ì¼ ëª©í‘œë¥¼ ë°˜ë³µí•˜ë©´ì„œ ë†€ë„ ë§Œí¼ ë‹¤ì–‘í•œ ì§€ëŠ¥ì  í–‰ë™ì´ ë‚˜íƒ€ë‚˜ê²Œ ë©ë‹ˆë‹¤. í•µì‹¬ ì›ë¦¬ë¥¼ ë‹¨ê³„ë³„ë¡œ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "1. ë°ì´í„° ì¤€ë¹„  \n",
      "   â€¢ ê³µê°œ ì›¹, ì±…, ìœ„í‚¤, ë…¼ë¬¸, ì½”ë“œ ë“± ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ë¥¼ ìˆ˜ì§‘Â·ì„¸ì •Â·ì¤‘ë³µ ì œê±°.  \n",
      "   â€¢ ë¬¸ì¥ì„ â€˜í† í°â€™(ë‹¨ì–´Â·ë¶€ë¶„ ë‹¨ì–´Â·ë¬¸ì) ë‹¨ìœ„ë¡œ ì˜ë¼ 5ë§Œ~10ë§Œ ê°œ ê·œëª¨ì˜ ì–´íœ˜ ì‚¬ì „(vocabulary)ì„ ë§Œë“­ë‹ˆë‹¤.  \n",
      "   â€¢ ê° í† í°ì€ ì •ìˆ˜ IDë¡œ ë°”ë€Œê³ , ëª¨ë¸ì€ ì´ ID ì‹œí€€ìŠ¤ë§Œ â€œë³´ê³ â€ í•™ìŠµí•©ë‹ˆë‹¤.\n",
      "\n",
      "2. ëª¨ë¸ êµ¬ì¡° â€“ íŠ¸ëœìŠ¤í¬ë¨¸ ë””ì½”ë”  \n",
      "   â€¢ ì´ Lê°œì˜ ì–´í…ì…˜-í”¼ë“œí¬ì›Œë“œ ë¸”ë¡ì´ ìŒ“ì¸ ìˆœì°¨ ìƒì„± ëª¨ë¸.  \n",
      "   â€¢ ì…€í”„-ì–´í…ì…˜ì€ â€œì§€ê¸ˆê¹Œì§€ ë‚˜ì˜¨ í† í°ë“¤ì„ ë™ì‹œì— ì°¸ê³ í•˜ì—¬ í˜„ì¬ ìœ„ì¹˜ì˜ í‘œí˜„ì„ ê°±ì‹ â€í•˜ëŠ” í–‰ë ¬ ì—°ì‚°.  \n",
      "   â€¢ ìœ„ì¹˜ ì¸ì½”ë”©(positional encoding)ìœ¼ë¡œ ë‹¨ì–´ ìˆœì„œ ì •ë³´ë¥¼ ë³´ì¡´.  \n",
      "   â€¢å› æœ(ì¸ê³¼) ë§ˆìŠ¤í¬ë¡œ â€œë¯¸ë˜ í† í°ì€ ë³´ì§€ ëª»í•˜ê²Œâ€ í•¨ â†’ ìê¸° íšŒê·€(auto-regressive) ìƒì„± ê°€ëŠ¥.  \n",
      "   â€¢ íŒŒë¼ë¯¸í„° ìˆ˜ = ìˆ˜ì‹­ ì–µ~ìˆ˜ì²œ ì–µ(ì˜ˆ: GPT-3 175B, GPT-4 ì¶”ì • 1.8T MoE).  \n",
      "   â€¢ í–‰ë ¬-ë²¡í„° ì—°ì‚°ë§Œìœ¼ë¡œ ë‹¤ìŒ í† í° í™•ë¥  P(token|context)ë¥¼ ì¶œë ¥.\n",
      "\n",
      "3. 1ë‹¨ê³„: ì‚¬ì „ í•™ìŠµ(Pre-training) â€“ ìˆ˜í¼ë¹„ì „ ì—†ìŒ  \n",
      "   ëª©ì  í•¨ìˆ˜: ìµœëŒ€ ìš°ë„(Maximum Likelihood)  \n",
      "        L = Î£_t log P(w_t | w_1 â€¦ w_{tâˆ’1}; Î¸)  \n",
      "   â€¢ í•œ ì—í­ë‹¹ ìˆ˜ì¡° í† í°ì„ 1~2ê°œì›”ê°„ A100/H100 GPU ìˆ˜ì²œ ëŒ€ë¡œ í•™ìŠµ.  \n",
      "   â€¢ ê²½ì‚¬ ì†Œì‹¤/í­ì£¼ë¥¼ ë§‰ê¸° ìœ„í•´ LayerNorm, Residual, AdamW, AMP, BF16/FP16, gradient clipping ë“± ê¸°ë²• ì‚¬ìš©.  \n",
      "   â€¢ ê²°ê³¼: ì„¸ê³„ ì§€ì‹Â·ë¬¸ë²•Â·ì¶”ë¡ Â·ì½”ë“œ ë¬¸ë²• ë“±ì„ í™•ë¥  ë¶„í¬ì— ë…¹ì„(â€˜ê¸°ì € ëª¨ë¸â€™).\n",
      "\n",
      "4. 2ë‹¨ê³„: ë³´ìƒ ëª¨ë¸ í•™ìŠµ(Reward Model, RM)  \n",
      "   â€¢ ê°™ì€ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ ëª¨ë¸ì´ ë§Œë“  4~9ê°œ ë‹µë³€ì„ ì‚¬ëŒì´ 1~5ì  ìˆœìœ„ ë§¤ê¹€.  \n",
      "   â€¢ ì´ (í”„ë¡¬í”„íŠ¸, ë‹µë³€, ì ìˆ˜) ìŒìœ¼ë¡œ RMì„ í•™ìŠµâ†’â€œì–´ë–¤ ë‹µë³€ì´ ì‚¬ëŒì—ê²Œ ë” ë†’ì€ ì ìˆ˜ì¼ í™•ë¥ â€ì„ ì˜ˆì¸¡í•˜ë„ë¡ í•¨.  \n",
      "   â€¢ RMì˜ ì¶œë ¥ ìŠ¤ì¹¼ë¼ëŠ” ì´í›„ ê°•í™”í•™ìŠµ ë³´ìƒè®¯í˜¸ë¡œ ì‚¬ìš©.\n",
      "\n",
      "5. 3ë‹¨ê³„: ê°•í™”í•™ìŠµ ë¯¸ì„¸ ì¡°ì •(RLHF, Reinforcement Learning from Human Feedback)  \n",
      "   ì•Œê³ ë¦¬ì¦˜: PPO(Proximal Policy Optimization)  \n",
      "   â€¢æ¼”actor = ì •ì±… Ï€_Î¸(ê¸°ì € ëª¨ë¸), critic = ê°’ í•¨ìˆ˜ V_Ï†(ì„ íƒì ).  \n",
      "   â€¢ ë§¤ ìŠ¤í…  \n",
      "     â€“ í”„ë¡¬í”„íŠ¸ ë°°ì¹˜ë¥¼ ìƒ˜í”Œë§.  \n",
      "     â€“ Ï€_Î¸ë¡œ ë‹µë³€ ìƒì„± â†’ RMì´ ë³´ìƒ r.  \n",
      "     â€“ KL-í˜ë„í‹° ì¶”ê°€: Ï€_Î¸ê°€ ì›ë³¸ ëª¨ë¸ Ï€_SFTì™€ ë„ˆë¬´ ë©€ì–´ì§€ì§€ ì•Šë„ë¡.  \n",
      "     â€“ PPOë¡œ ì •ì±… ê°±ì‹ .  \n",
      "   â€¢ ìˆ˜ë§Œ~ìˆ˜ì‹­ë§Œ ê±´ì˜ human preference ë°˜ë³µ â†’ â€˜ì•ˆì „Â·ë„ì›€Â·ê³µì •ì„±â€™ì´ í–¥ìƒ.\n",
      "\n",
      "6. íŒŒë¼ë¯¸í„° íš¨ìœ¨ ê¸°ë²•(ì„ íƒ)  \n",
      "   â€¢ LoRA, QLoRA, AdaLoRA: í•™ìŠµ ê°€ëŠ¥ í–‰ë ¬ì„ ì €ë­í¬ ë¶„í•´ë¡œ ì¤„ì—¬ GPU ë©”ëª¨ë¦¬ â†“.  \n",
      "   â€¢ ìµœì¢… ê°€ì¤‘ì¹˜ =å‡çµ ê¸°ë³¸ ëª¨ë¸ + Î”W(ì €ë­í¬ ì–´ëŒ‘í„°).\n",
      "\n",
      "7. ìƒì„±(ì¶”ë¡ ) ê³¼ì •  \n",
      "   1) ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ë¥¼ í† í° ì‹œí€€ìŠ¤ë¡œ ë³€í™˜.  \n",
      "   2) íŠ¸ëœìŠ¤í¬ë¨¸ ë””ì½”ë”ë¥¼ í•œ ë²ˆì— ì „ë°© ê³„ì‚° â†’ ë‹¤ìŒ í† í° í™•ë¥  ë²¡í„°.  \n",
      "   3) ìƒ˜í”Œë§ ì „ëµ(greedy, beam-search, top-k, top-p, temperature)ìœ¼ë¡œ í† í° 1ê°œ ì„ íƒ.  \n",
      "   4) ì„ íƒëœ í† í°ì„ ë‹¤ì‹œ ì…ë ¥ì— ë¶™ì—¬ ë°˜ë³µ.  \n",
      "   5) ì¢…ë£Œ í† í°()ì´ ë‚˜ì˜¤ê±°ë‚˜ ìµœëŒ€ ê¸¸ì´ ë„ë‹¬ ì‹œ ì¢…ë£Œ.  \n",
      "   â€¢ KV-ìºì‹±, ë²¡í„° ì–‘ìí™”, GPU ë³‘ë ¬í™”ë¡œ ì‹¤ì‹œê°„ ì‘ë‹µ ì†ë„ í™•ë³´.\n",
      "\n",
      "8. ì™œ â€˜ëŒ€í™”â€™ê°€ ê°€ëŠ¥í•œê°€?  \n",
      "   â€¢ ì‚¬ì „ í•™ìŠµì—ì„œ ë‹¤ì–‘í•œ ì§ˆë¬¸-ì‘ë‹µ, ëŒ€í™”ì²´ ë¬¸ì¥ì„ ëŒ€ëŸ‰ í¬í•¨.  \n",
      "   â€¢ RLHFë¡œ â€œì‚¬ìš©ì ì˜ë„ ì¶©ì¡±â€ ë°©í–¥ì„ ëª…ì‹œì ìœ¼ë¡œ ê°•í™”.  \n",
      "   â€¢ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°(4KÂ·8KÂ·32KÂ·128K í† í°) ë•ë¶„ì— ì´ì „ ëŒ€í™” ê¸°ì–µ ê°€ëŠ¥.  \n",
      "   â€» ë‹¨, ë‚´ë¶€ì—ëŠ” â€˜ëŒ€í™” ìƒíƒœâ€™ë¥¼ ìœ ì§€í•˜ëŠ” ë³„ë„ ë©”ëª¨ë¦¬ê°€ ì—†ê³ , ë§¤ í„´ ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ë§Œìœ¼ë¡œ ë‹¤ìŒ í† í°ì„ ì˜ˆì¸¡í•  ë¿ì…ë‹ˆë‹¤.\n",
      "\n",
      "9. ì§€ì‹ í•œê³„ì™€ ì£¼ìš” ë¬¸ì œ  \n",
      "   â€¢ í™˜ìì„±(Hallucination): í™•ë¥ ì  ìƒì„±ì˜ ë¶€ì‘ìš©ìœ¼ë¡œ ì‚¬ì‹¤ì´ í‹€ë¦´ ìˆ˜ ìˆìŒ.  \n",
      "   â€¢ í›ˆë ¨ ë°ì´í„° Cut-off: ê·¸ ì´í›„ ì‚¬ì‹¤ì€ ì•Œì§€ ëª»í•¨.  \n",
      "   â€¢ í¸í–¥ì„±: ì›¹ ë¬¸ì„œì— í¬í•¨ëœ ì„±ë³„Â·ì¸ì¢…Â·ì •ì¹˜ì  í¸í–¥ì´ ëª¨ë¸ì—ë„ ë°˜ì˜.  \n",
      "   â€¢ ì¶”ë¡  í•œê³„: ë³µì¡í•œ ìˆ˜í•™Â·ë…¼ë¦¬ ë¬¸ì œì—ì„œëŠ” í‹€ë¦´ í™•ë¥  ë†’ìŒ.  \n",
      "   â€¢ ë¹„ê²°ì •ì : temperature â‰ 0ì´ë©´ ê°™ì€ ì…ë ¥ì—ë„ ë§¤ë²ˆ ë‹¤ë¥¸ ë‹µë³€.\n",
      "\n",
      "10. ìš”ì•½  \n",
      "ChatGPTëŠ” â€˜ê±°ëŒ€í•œ íŠ¸ëœìŠ¤í¬ë¨¸ ë””ì½”ë”â€™ì—  \n",
      " 1) ìˆ˜ì¡° í† í°ìœ¼ë¡œ ë‹¤ìŒ í† í° ì˜ˆì¸¡(Self-Supervised Pre-training)  \n",
      " 2) ì‚¬ëŒ ì„ í˜¸ë„ë¥¼ ë°˜ì˜í•œ ë³´ìƒ ëª¨ë¸ í•™ìŠµ  \n",
      " 3) PPO ê¸°ë°˜ RL ë¯¸ì„¸ ì¡°ì •(RLHF)  \n",
      "ì„ ê±°ì³ íƒ„ìƒí•©ë‹ˆë‹¤. í•µì‹¬ì€ ì˜¤ì§ â€œë‹¤ìŒ í† í°ì„ í™•ë¥ ì ìœ¼ë¡œ ì˜ˆì¸¡â€í•˜ëŠ” ë‹¨ìˆœí•œ ëª©í‘œì— ë°©ëŒ€í•œ ë°ì´í„°Â·íŒŒë¼ë¯¸í„°Â·ì—°ì‚°Â·ë³´ìƒ ì‹ í˜¸ë¥¼ ì£¼ì…í•¨ìœ¼ë¡œì¨, ì½ê¸°Â·ì“°ê¸°Â·ìš”ì•½Â·ë²ˆì—­Â·ì½”ë“œ ìƒì„±Â·ì¶”ë¡ Â·ëŒ€í™” ë“± ë³µì¡í•œ ì§€ëŠ¥ í–‰ë™ì´ â€˜ë‚˜íƒ€ë‚˜ê²Œâ€™(emerge) í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì²´ì¸ì„ ìƒì„±í•˜ì—¬ í˜¸ì¶œí•˜ê¸°\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"topic\":\"AI\", \"model_name\":\"ChatGPT\"})\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) ChatPromptTemplate\n",
    "* SystemMessagePromptTemplateì™€ HumanMessagePromptTemplate í´ë˜ìŠ¤ ì‚¬ìš©\n",
    "* ê°ì²´ ì§€í–¥ì  ì ‘ê·¼ - Message ê°ì²´ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ìƒì„± ê°€ëŠ¥\n",
    "* ì—¬ëŸ¬ ì¡°ê±´ì— ë”°ë¼ ë‹¤ë¥¸ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„ íƒ\n",
    "\n",
    "```python\n",
    "if user_is_beginner:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"ì´ˆë³´ìë¥¼ ìœ„í•œ ì„¤ëª…: {topic}\")\n",
    "else:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"ì „ë¬¸ê°€ë¥¼ ìœ„í•œ ìƒì„¸ ë¶„ì„: {topic}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ChatMessagePromptTemplate í™œìš©\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    ChatMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ê°œë³„ ë©”ì‹œì§€ í…œí”Œë¦¿ ì •ì˜\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI expert in {topic}. Please provide clear and detailed explanations.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplateë¡œ ë©”ì‹œì§€ë“¤ì„ ë¬¶ê¸°\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# ë©”ì‹œì§€ ìƒì„±\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"What is deep learning?\")\n",
    "\n",
    "# LLM í˜¸ì¶œ\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatMessagePromptTemplateëŠ” ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ë©”ì‹œì§€(ì‹œìŠ¤í…œ, ì¸ê°„, AI)ë¥¼ ì¡°í•©í•˜ì—¬ ë³µì¡í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\n",
    "* SystemMessagePromptTemplate: ì´ í…œí”Œë¦¿ì€ AI ëª¨ë¸ì—ê²Œ ì—­í• ì„ ë¶€ì—¬í•˜ê±°ë‚˜ ì „ë°˜ì ì¸ ê·œì¹™ì„ ì„¤ì •í•˜ëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ë§Œë“­ë‹ˆë‹¤. ìœ„ì˜ ì˜ˆì‹œì—ì„œëŠ” \"ë²ˆì—­ì„ ë„ì™€ì£¼ëŠ” ìœ ìš©í•œ ë„ìš°ë¯¸\"ë¼ëŠ” ì—­í• ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "* HumanMessagePromptTemplate: ì´ í…œí”Œë¦¿ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ë‚˜ ìš”ì²­ì„ ë‹´ëŠ” ì¸ê°„ ë©”ì‹œì§€ë¥¼ ë§Œë“­ë‹ˆë‹¤. ì•„ë˜ì˜ ì˜ˆì‹œì—ì„œëŠ” ë²ˆì—­í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ìŠµë‹ˆë‹¤.\n",
    "* ChatPromptTemplate.from_messages: ì´ í´ë˜ìŠ¤ ë©”ì„œë“œëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€, ì¸ê°„ ë©”ì‹œì§€ ë“± ì—¬ëŸ¬ ì¢…ë¥˜ì˜ MessagePromptTemplate ê°ì²´ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ì•„ í•˜ë‚˜ì˜ ì±„íŒ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤.\n",
    "* format_messages: ì´ ë©”ì„œë“œëŠ” ì •ì˜ëœ í…œí”Œë¦¿ì— ì‹¤ì œ ê°’ì„ ì±„ì›Œ ë„£ì–´ [SystemMessage, HumanMessage] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ì´ ë¦¬ìŠ¤íŠ¸ëŠ” ì±„íŒ… ëª¨ë¸(Chat Model) ì— ë°”ë¡œ ì „ë‹¬ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant that translates English to Korean.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I love programming.', additional_kwargs={}, response_metadata={})]\n",
      "ë‚˜ëŠ” í”„ë¡œê·¸ë˜ë°ì„ ì‚¬ë‘í•´.\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# 1. SystemMessagePromptTemplateì™€ HumanMessagePromptTemplate ìƒì„±\n",
    "# SystemMessagePromptTemplateëŠ” ëª¨ë¸ì˜ í˜ë¥´ì†Œë‚˜ ë˜ëŠ” ê¸°ë³¸ ì§€ì¹¨ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "system_template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# HumanMessagePromptTemplateëŠ” ì‚¬ìš©ìë¡œë¶€í„° ë°›ëŠ” ì…ë ¥ í”„ë¡¬í”„íŠ¸ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "human_template = \"{text_to_translate}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# 2. ChatPromptTemplate ìƒì„±\n",
    "# ìœ„ì—ì„œ ë§Œë“  ë‘ í…œí”Œë¦¿ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë¬¶ì–´ ChatPromptTemplateì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# 3. í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…\n",
    "# chat_prompt_template.format_messages()ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "# ì´ í•¨ìˆ˜ëŠ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ ì…ë ¥ ë³€ìˆ˜ë¥¼ ë°›ìŠµë‹ˆë‹¤.\n",
    "formatted_prompt = chat_prompt_template.format_messages(\n",
    "    input_language=\"English\",\n",
    "    output_language=\"Korean\",\n",
    "    text_to_translate=\"I love programming.\"\n",
    ")\n",
    "\n",
    "# 4. ê²°ê³¼ ì¶œë ¥\n",
    "print(formatted_prompt)\n",
    "\n",
    "# LLM í˜¸ì¶œ\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) FewShotPromptTemplate\n",
    "* FewShotPromptTemplateì€ ëª¨ë¸ì´ íŠ¹ì • í˜•ì‹ì„ ë”°ë¥´ê²Œ í•˜ê±°ë‚˜, ì¼ê´€ëœ ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ ìœ ë„í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\n",
    "* ë„ë©”ì¸ ì§€ì‹ì´ í•„ìš”í•˜ê±°ë‚˜, AIê°€ ì˜¤ë‹µì„ ì¤„ì´ê³  ë” ì‹ ë¢°í•  ë§Œí•œ ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ í•´ì•¼ í•  ë•Œ íš¨ê³¼ì ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-1) PromptTemplateì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "íƒœì–‘ê³„ í–‰ì„±(íƒœì–‘ì—ì„œ ë©€ì–´ì§€ëŠ” ìˆœ)\n",
      "\n",
      "1. ìˆ˜ì„±  \n",
      "   - ì§€ë¦„: ì§€êµ¬ì˜ 38%  \n",
      "   - íŠ¹ì§•: í‘œë©´ ì˜¨ë„ ë³€í™” ê·¹ì‹¬, ë‹¬ë³´ë‹¤ ì‘ìŒ\n",
      "\n",
      "2. ê¸ˆì„±  \n",
      "   - ì§€ë¦„: ì§€êµ¬ 95%  \n",
      "   - íŠ¹ì§•: ì´ì‚°í™”íƒ„ì†Œ ëŒ€ê¸°Â·ì˜¨ì‹¤íš¨ê³¼ë¡œ 460 Â°C, ë°¤ë‚® êµ¬ë¶„ ì•ˆ ë¨\n",
      "\n",
      "3. ì§€êµ¬  \n",
      "   - ìœ ì¼í•œ ì•¡ì²´ í•´ì–‘Â·ìƒëª… ì¡´ì¬\n",
      "\n",
      "4. í™”ì„±  \n",
      "   - ì§€ë¦„: ì§€êµ¬ 53%  \n",
      "   - íŠ¹ì§•: ì ìƒ‰ ì‚¬ë§‰Â·ê·¹å† , ê³¼ê±° ìœ ìˆ˜ í”ì , ìœ„ì„± 2ê°œ\n",
      "\n",
      "5. ëª©ì„±  \n",
      "   - ì§ˆëŸ‰: ë‹¤ë¥¸ í–‰ì„± í•©ì¹œ ê²ƒì˜ 2ë°°  \n",
      "   - íŠ¹ì§•: ëŒ€í­í’(ì ì ), ìœ„ì„± 90ì—¬ ê°œ(ì´ì˜¤Â·ê°€ë‹ˆë©”ë° ë“±)\n",
      "\n",
      "6. í† ì„±  \n",
      "   - íŠ¹ì§•: í˜„ì €í•œ ê³ ë¦¬, ìœ„ì„± 80ì—¬ ê°œ(í‹°íƒ„Â·ì—”ì¼ˆë¼ë„ìŠ¤)\n",
      "\n",
      "7. ì²œì™•ì„±  \n",
      "   - íŠ¹ì§•: ì˜†ìœ¼ë¡œ ëˆ„ìš´ ìì „ì¶•(98Â°), ê³ ë¦¬Â·ìœ„ì„± 27ê°œ\n",
      "\n",
      "8. í•´ì™•ì„±  \n",
      "   - íŠ¹ì§•: ì´ˆìŒì† ë°”ëŒ, ìœ„ì„± 14ê°œ(íŠ¸ë¦¬í†¤)\n",
      "\n",
      "â€» í™”ì„±ê³¼ ëª©ì„± ì‚¬ì´ì— â€˜ì†Œí–‰ì„±ëŒ€â€™, í•´ì™•ì„± ê¶¤ë„ ë„ˆë¨¸ì— â€˜ì¹´ì´í¼ëŒ€â€™ ì¡´ì¬\n"
     ]
    }
   ],
   "source": [
    "# PromptTemplateì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# chain ì‹¤í–‰\n",
    "result = llm.invoke(\"íƒœì–‘ê³„ì˜ í–‰ì„±ë“¤ì„ ê°„ëµíˆ ì •ë¦¬í•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "print(type(result))\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-2) FewShotChatMessagePromptTemplate ì‚¬ìš©í•˜ëŠ” ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x00000204E9DFF110> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000204E9E71280> root_client=<openai.OpenAI object at 0x00000204E98B43B0> root_async_client=<openai.AsyncOpenAI object at 0x00000204E9E3D1F0> model_name='moonshotai/kimi-k2-instruct-0905' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n",
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ê³¼í•™ êµìœ¡ìì…ë‹ˆë‹¤.'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'input': 'ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.', 'output': '### ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™\\n1. **ê´€ì„±ì˜ ë²•ì¹™**: í˜ì´ ì‘ìš©í•˜ì§€ ì•Šìœ¼ë©´ ë¬¼ì²´ëŠ” ê³„ì† ê°™ì€ ìƒíƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\\n2. **ê°€ì†ë„ì˜ ë²•ì¹™**: ë¬¼ì²´ì— í˜ì´ ì‘ìš©í•˜ë©´, í˜ê³¼ ì§ˆëŸ‰ì— ë”°ë¼ ê°€ì†ë„ê°€ ê²°ì •ë©ë‹ˆë‹¤.\\n3. **ì‘ìš©-ë°˜ì‘ìš© ë²•ì¹™**: ëª¨ë“  í˜ì—ëŠ” í¬ê¸°ê°€ ê°™ê³  ë°©í–¥ì´ ë°˜ëŒ€ì¸ í˜ì´ ì‘ìš©í•©ë‹ˆë‹¤.'}, {'input': 'ì§€êµ¬ì˜ ëŒ€ê¸° êµ¬ì„± ìš”ì†Œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.', 'output': '### ì§€êµ¬ ëŒ€ê¸°ì˜ êµ¬ì„±\\n- **ì§ˆì†Œ (78%)**: ëŒ€ê¸°ì˜ ëŒ€ë¶€ë¶„ì„ ì°¨ì§€í•©ë‹ˆë‹¤.\\n- **ì‚°ì†Œ (21%)**: ìƒëª…ì²´ê°€ í˜¸í¡í•˜ëŠ” ë° í•„ìš”í•©ë‹ˆë‹¤.\\n- **ì•„ë¥´ê³¤ (0.93%)**: ë°˜ì‘ì„±ì´ ë‚®ì€ ê¸°ì²´ì…ë‹ˆë‹¤.\\n- **ì´ì‚°í™”íƒ„ì†Œ (0.04%)**: ê´‘í•©ì„± ë° ì˜¨ì‹¤ íš¨ê³¼ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000204E9DFF110>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000204E9E71280>, root_client=<openai.OpenAI object at 0x00000204E98B43B0>, root_async_client=<openai.AsyncOpenAI object at 0x00000204E9E3D1F0>, model_name='moonshotai/kimi-k2-instruct-0905', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "ì–‘ìì»´í“¨í„°ëŠ” â€˜ìŠˆí¼ ë„ë§ˆâ€™ë‘ ë¹„ìŠ·í•´ìš”.\n",
      "\n",
      "1. ì¼ë°˜ ë„ë§ˆ(ì»´í“¨í„°)  \n",
      "   - ì¥ê¸° ë§ì´ í•˜ë‚˜ì”© ë“¤ì–´ê°€ìš”.  \n",
      "   - 1 ì•„ë‹ˆë©´ 0, ë”± í•˜ë‚˜ì˜ ìƒíƒœë§Œ ê°€ëŠ¥í•´ìš”.\n",
      "\n",
      "2. ì–‘ì ë„ë§ˆ(ì–‘ìì»´í“¨í„°)  \n",
      "   - ì¥ê¸° ë§ì´ â€˜íšŒì „íŒâ€™ ìœ„ì— ìˆì–´ìš”.  \n",
      "   - 0ì¸ ë™ì‹œ 1ì¼ ìˆ˜ë„ ìˆì–´ìš”.  \n",
      "   - ì—¬ëŸ¬ ê°œì˜ ë§ì„ í•œêº¼ë²ˆì— ì„ìœ¼ë©´ í•œ ë²ˆì— ë§ì€ ê¸¸ì„ â€˜ë™ì‹œì—â€™ ë³¼ ìˆ˜ ìˆì–´ìš”.\n",
      "\n",
      "ê²°ë¡   \n",
      "ì–‘ìì»´í“¨í„°ëŠ” ì´ëŸ° â€˜ë™ì‹œì— ì—¬ëŸ¬ ê¸¸ ë³´ê¸°â€™ ëŠ¥ë ¥ìœ¼ë¡œ ë³µì¡í•œ ë¬¸ì œë¥¼ í›¨ì”¬ ë¹¨ë¦¬ í’€ì–´ìš”.\n"
     ]
    }
   ],
   "source": [
    "# FewShotChatMessagePromptTemplate ì‚¬ìš©í•˜ëŠ” ê²½ìš°\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.\",\n",
    "        \"output\": \"\"\"### ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™\n",
    "1. **ê´€ì„±ì˜ ë²•ì¹™**: í˜ì´ ì‘ìš©í•˜ì§€ ì•Šìœ¼ë©´ ë¬¼ì²´ëŠ” ê³„ì† ê°™ì€ ìƒíƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\n",
    "2. **ê°€ì†ë„ì˜ ë²•ì¹™**: ë¬¼ì²´ì— í˜ì´ ì‘ìš©í•˜ë©´, í˜ê³¼ ì§ˆëŸ‰ì— ë”°ë¼ ê°€ì†ë„ê°€ ê²°ì •ë©ë‹ˆë‹¤.\n",
    "3. **ì‘ìš©-ë°˜ì‘ìš© ë²•ì¹™**: ëª¨ë“  í˜ì—ëŠ” í¬ê¸°ê°€ ê°™ê³  ë°©í–¥ì´ ë°˜ëŒ€ì¸ í˜ì´ ì‘ìš©í•©ë‹ˆë‹¤.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"ì§€êµ¬ì˜ ëŒ€ê¸° êµ¬ì„± ìš”ì†Œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\",\n",
    "        \"output\": \"\"\"### ì§€êµ¬ ëŒ€ê¸°ì˜ êµ¬ì„±\n",
    "- **ì§ˆì†Œ (78%)**: ëŒ€ê¸°ì˜ ëŒ€ë¶€ë¶„ì„ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
    "- **ì‚°ì†Œ (21%)**: ìƒëª…ì²´ê°€ í˜¸í¡í•˜ëŠ” ë° í•„ìš”í•©ë‹ˆë‹¤.\n",
    "- **ì•„ë¥´ê³¤ (0.93%)**: ë°˜ì‘ì„±ì´ ë‚®ì€ ê¸°ì²´ì…ë‹ˆë‹¤.\n",
    "- **ì´ì‚°í™”íƒ„ì†Œ (0.04%)**: ê´‘í•©ì„± ë° ì˜¨ì‹¤ íš¨ê³¼ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# ì˜ˆì œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate ì ìš©\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ê³¼í•™ êµìœ¡ìì…ë‹ˆë‹¤.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± ë° ì²´ì¸ êµ¬ì„±\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "chain = final_prompt | llm\n",
    "print(llm)\n",
    "print(chain)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "result = chain.invoke({\"input\": \"ì–‘ìì»´í“¨íŒ…ì— ëŒ€í•˜ì—¬ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-1) PartialPrompt \n",
    "* í”„ë¡¬í”„íŠ¸ë¥¼ ë” ë™ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆìœ¼ë©°, AI ì‘ë‹µì„ ë” ì¼ê´€ì„± ìˆê²Œ ì¡°ì • ê°€ëŠ¥í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " í”„ë¡¬í”„íŠ¸: ê°€ì„ì— ì¼ì–´ë‚˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒì€ íƒœí’ ë°œìƒì´ ë§ë‚˜ìš”?         ê°€ì„ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ì§€êµ¬ê³¼í•™ í˜„ìƒì„ 3ê°œ ì•Œë ¤ì£¼ì„¸ìš”\n",
      " ëª¨ë¸ ì‘ë‹µ: ê°€ì„ì— ì¼ì–´ë‚˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒì€ **íƒœí’ ë°œìƒ**ì´ ë§ê¸´ í•˜ì§€ë§Œ, íƒœí’ì€ **ì—¬ë¦„~ê°€ì„**ì— ê±¸ì³ ë°œìƒí•˜ë©°, **ê°€ì„ì— íŠ¹íˆ ë¹ˆë²ˆ**í•´ì§€ëŠ” í¸ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ **ê°€ì„ì—ë§Œ** ë°œìƒí•˜ëŠ” ê²ƒì€ ì•„ë‹ˆì—ìš”.\n",
      "\n",
      "---\n",
      "\n",
      "### âœ… ê°€ì„ì— **ì£¼ë¡œ** ì¼ì–´ë‚˜ëŠ” ì§€êµ¬ê³¼í•™ í˜„ìƒ 3ê°€ì§€:\n",
      "\n",
      "1. **ì‹œì°¨í˜„ìƒ(Equinox)**  \n",
      "   - 9ì›” 22ì¼~23ì¼ê²½ ë°œìƒí•˜ëŠ” **ì¶”ë¶„(ç§‹åˆ†)**ìœ¼ë¡œ, ë‚®ê³¼ ë°¤ì˜ ê¸¸ì´ê°€ ê°™ì•„ì§€ëŠ” í˜„ìƒì…ë‹ˆë‹¤.  \n",
      "   - ì§€êµ¬ì˜ ìì „ì¶•ì´ íƒœì–‘ì— ìˆ˜ì§ì´ ë˜ëŠ” ì‹œì .\n",
      "\n",
      "2. **ì„±ì¸µê¶Œ ëŒí’(SSW: Sudden Stratospheric Warming)**  \n",
      "   - ë¶ë°˜êµ¬ì—ì„œ ê²¨ìš¸ ì „í™˜ê¸°(10~11ì›”)ì— ê°€ê¹Œì›Œì§€ë©° ë°œìƒí•˜ëŠ” **ì„±ì¸µê¶Œì˜ ê¸‰ê²©í•œ ì˜¨ë„ ìƒìŠ¹** í˜„ìƒ.  \n",
      "   - ì´í›„ ë¶ê·¹ ì§„ë™(AO) ì•½í™”ë¡œ ì¸í•´ **í•œíŒŒ**ë‚˜ **ì´ìƒ ê¸°í›„**ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŒ.\n",
      "\n",
      "3. **ê°€ì„ íƒœí’(ç§‹å°)**  \n",
      "   - 9~10ì›”ì— ì§‘ì¤‘ ë°œìƒí•˜ëŠ” íƒœí’.  \n",
      "   - í•´ìˆ˜ë©´ ì˜¨ë„ê°€ ì—¬ë¦„ë§Œí¼ ë†’ê³ , ì œíŠ¸ê¸°ë¥˜ê°€ ë‚¨í•˜í•˜ë©´ì„œ **ê°•ë ¥í•œ íƒœí’**ì´ ìì£¼ ë°œìƒ.  \n",
      "   - í•œêµ­, ì¼ë³¸, ì¤‘êµ­ ë™í•´ì•ˆì— í° í”¼í•´ë¥¼ ì¤Œ.\n",
      "\n",
      "---\n",
      "\n",
      "### ìš”ì•½\n",
      "- **íƒœí’**ì€ ê°€ì„ì˜ ëŒ€í‘œ í˜„ìƒ ì¤‘ í•˜ë‚˜ì§€ë§Œ, **ê°€ì„ì—ë§Œ** ë°œìƒí•˜ëŠ” ê±´ ì•„ë‹™ë‹ˆë‹¤.  \n",
      "- **ì¶”ë¶„**, **SSW**, **ê°€ì„ íƒœí’**ì´ ê°€ì„ì— **íŠ¹íˆ ëšœë ·í•˜ê²Œ ë‚˜íƒ€ë‚˜ëŠ”** ì§€êµ¬ê³¼í•™ í˜„ìƒì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ê³„ì ˆì„ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ (ë‚¨ë°˜êµ¬/ë¶ë°˜êµ¬ ê³ ë ¤)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # ë¶ë°˜êµ¬ (ê¸°ë³¸ê°’)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ë´„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ì—¬ë¦„\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ê°€ì„\"\n",
    "        else:\n",
    "            return \"ê²¨ìš¸\"\n",
    "    else:  # ë‚¨ë°˜êµ¬ (ê³„ì ˆ ë°˜ëŒ€)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ê°€ì„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ê²¨ìš¸\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ë´„\"\n",
    "        else:\n",
    "            return \"ì—¬ë¦„\"\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ (ë¶€ë¶„ ë³€ìˆ˜ ì ìš©)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{season}ì— ì¼ì–´ë‚˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒì€ {phenomenon}ì´ ë§ë‚˜ìš”? \\\n",
    "        {season}ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ì§€êµ¬ê³¼í•™ í˜„ìƒì„ 3ê°œ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
    "    input_variables=[\"phenomenon\"],  # ì‚¬ìš©ì ì…ë ¥ í•„ìš”\n",
    "    partial_variables={\"season\": get_current_season()}  # ë™ì ìœ¼ë¡œ ê³„ì ˆ ê°’ í• ë‹¹\n",
    ")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "# íŠ¹ì • ê³„ì ˆì˜ í˜„ìƒ ì§ˆì˜\n",
    "query = prompt.format(phenomenon=\"íƒœí’ ë°œìƒ\")\n",
    "result = llm.invoke(query)\n",
    "\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\" í”„ë¡¬í”„íŠ¸: {query}\")\n",
    "print(f\" ëª¨ë¸ ì‘ë‹µ: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ê³„ì ˆ: ê°€ì„\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ê³„ì ˆì„ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ (ë‚¨ë°˜êµ¬/ë¶ë°˜êµ¬ ê³ ë ¤)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # ë¶ë°˜êµ¬ (ê¸°ë³¸ê°’)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ë´„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ì—¬ë¦„\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ê°€ì„\"\n",
    "        else:\n",
    "            return \"ê²¨ìš¸\"\n",
    "    else:  # ë‚¨ë°˜êµ¬ (ê³„ì ˆ ë°˜ëŒ€)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ê°€ì„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ê²¨ìš¸\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ë´„\"\n",
    "        else:\n",
    "            return \"ì—¬ë¦„\"\n",
    "\n",
    "# Step 1: í˜„ì¬ ê³„ì ˆ ê²°ì •\n",
    "season_name = get_current_season()  # ê³„ì ˆ ê°’ ì–»ê¸°\n",
    "print(f\"í˜„ì¬ ê³„ì ˆ: {season_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ê°€ì„ì— ë°œìƒí•˜ëŠ” ìì—° í˜„ìƒ:\n",
      "ê°€ì„ì² ì— ëšœë ·í•˜ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒ 3ê°€ì§€ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "1. ì‹œë² ë¦¬ì•„ ê³ ê¸°ì•• í™•ì¥  \n",
      "   ì•„ì‹œì•„ ëŒ€ë¥™ì˜ ì‹œë² ë¦¬ì•„ ìƒê³µì—ì„œ ë°œë‹¬í•œ í•œë­ê³ ê¸°ì••ì´ ì ì°¨ ì„¸ë ¥ì„ í‚¤ì›Œ ë™ì•„ì‹œì•„ ìª½ìœ¼ë¡œ í™•ì¥í•©ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ì¤‘êµ­ ë¶ë¶€Â·í•œë°˜ë„Â·ì¼ë³¸ì— ë§‘ê³  ê±´ì¡°í•œ ë‚ ì”¨ê°€ ì´ì–´ì§€ë©´ì„œ ê¸°ì˜¨ì´ ë¹ ë¥´ê²Œ ë–¨ì–´ì§€ê³ , ìš°ë¦¬ë‚˜ë¼ì—ë„ â€˜ìŒ€ìŒ€í•œ ê°€ì„ë°”ëŒâ€™ê³¼ â€˜ì¼êµì°¨â€™ê°€ ëšœë ·í•´ì§‘ë‹ˆë‹¤.\n",
      "\n",
      "2. ì‚°ì•… ì§€í˜•ì—ì„œì˜ ì˜¨ëŒ€ ì €ê¸°ì••(ê°€ì„ì¥ë§ˆ)  \n",
      "   ì—¬ë¦„ì²  ëª¬ìˆ¨ì´ ì•½í•´ì§€ë©´ì„œ ë¶íƒœí‰ì–‘ ê³ ê¸°ì••ì´ ë‚¨í•˜í•˜ê³ , ê·¸ ì‚¬ì´ì—ì„œ ì¤‘êµ­ ëŒ€ë¥™ì„ ë”°ë¼ ë™ì§„í•˜ëŠ” ë‹¨íŒŒ ì €ê¸°ì••ì´ ë¹ˆë²ˆíˆ í˜•ì„±ë©ë‹ˆë‹¤. íŠ¹íˆ 9~10ì›” í•œë°˜ë„ ì‚°ì•…ì§€ì—­(íƒœë°±Â·ì†Œë°±ì‚°ë§¥)ì—ì„œëŠ” ì§€í˜• íš¨ê³¼ê°€ ë”í•´ì ¸ ì§‘ì¤‘í˜¸ìš°ê°€ ë°œìƒí•˜ëŠ”ë°, ì´ë¥¼ í”íˆ â€˜ê°€ì„ì¥ë§ˆâ€™ë¼ ë¶€ë¦…ë‹ˆë‹¤.\n",
      "\n",
      "3. ë¶ê·¹ ì§„ë™(ì•„í¬í‹± ì˜¤ì‹¤ë ˆì´ì…˜)ì˜ ì–‘ìƒ ì „í™˜  \n",
      "   ë¶ê·¹ê³¼ ì¤‘ìœ„ë„ ì‚¬ì´ì˜ ê¸°ì••ì°¨ê°€ ì»¤ì§€ëŠ” ìŒì˜ ì§„ë™(NAOÂ·AO)ì´ ëŠ¦ê°€ì„ì— ê°•í™”ë˜ë©´ ì œíŠ¸ê¸°ë¥˜ì´ ë¶ìƒí•˜ê³ , ì´ë¡œ ì¸í•´ í•œë°˜ë„ì— í•œíŒŒê°€ ì¦ì•„ì§€ë©° ê²¨ìš¸ì²  í•œíŒŒì˜ ì „ì¡° í˜„ìƒìœ¼ë¡œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: í•´ë‹¹ ê³„ì ˆì˜ ìì—° í˜„ìƒ ì¶”ì²œ\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{season}ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒ 3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. \"\n",
    "    \"ê° í˜„ìƒì— ëŒ€í•´ ê°„ë‹¨í•œ ì„¤ëª…ì„ í¬í•¨í•´ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì‚¬ìš©\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "# llm = ChatOpenAI(\n",
    "#     #api_key=OPENAI_API_KEY,\n",
    "#     base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "#     model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "#     temperature=0.0\n",
    "# )\n",
    "\n",
    "# ì²´ì¸ 2: ìì—° í˜„ìƒ ì¶”ì²œ (ì…ë ¥: ê³„ì ˆ â†’ ì¶œë ¥: ìì—° í˜„ìƒ ëª©ë¡)\n",
    "chain2 = (\n",
    "    {\"season\": lambda x : season_name}  # chain1ì˜ ì¶œë ¥ì„ season ë³€ìˆ˜ë¡œ ì „ë‹¬\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ì‹¤í–‰: í˜„ì¬ ê³„ì ˆì— ë”°ë¥¸ ìì—° í˜„ìƒ ì¶”ì²œ\n",
    "response = chain2.invoke({})\n",
    "print(f\"\\n {season_name}ì— ë°œìƒí•˜ëŠ” ìì—° í˜„ìƒ:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-2) PartialPrompt \n",
    "* API í˜¸ì¶œ ë°ì´í„°, ì‹œê°„ ì •ë³´, ì‚¬ìš©ì ì •ë³´ ë“±ì„ ë°˜ì˜í•  ë•Œ ë§¤ìš° ìœ ìš©í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " í”„ë¡¬í”„íŠ¸: í˜„ì¬ 1ë‹¬ëŸ¬ = 1386.92ì› ê¸°ì¤€ìœ¼ë¡œ í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. ì´ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.\n",
      " ëª¨ë¸ ì‘ë‹µ: í˜„ì¬ í™˜ìœ¨: **1 USD = 1,386.92 KRW**  \n",
      "(ê¸°ì¤€ ì‹œì : 2025ë…„ 6ì›” 22ì¼, ì‹¤ì‹œê°„ ìœ ë™ì„±ì— ë”°ë¼ ì†Œí­ ë³€ë™ ê°€ëŠ¥)\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ” 1. **í™˜ìœ¨ ìˆ˜ì¤€ ë¶„ì„**\n",
      "- **ê³ í™˜ìœ¨ êµ¬ê°„**: 1,380ì›ëŒ€ëŠ” 2022ë…„ 10ì›” ì´í›„ **ìµœê³  ìˆ˜ì¤€**ì— ê·¼ì ‘í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤.\n",
      "- **ì—°ì´ˆ ëŒ€ë¹„**: 2025ë…„ 1ì›” 1ì¼(ì•½ 1,270ì›) ëŒ€ë¹„ **ì•½ 9.2% ìƒìŠ¹** â†’ ì›í™” **ì•½ 9% ì ˆí•˜**ëœ ìƒí™©.\n",
      "- **ì‹¬ë¦¬ì  ì €í•­ì„ **: 1,400ì›ì´ **ì‹¬ë¦¬ì  ë§ˆì§€ë…¸ì„ **ìœ¼ë¡œ ì‘ìš© ì¤‘. 1,400ì› ëŒíŒŒ ì‹œ ìˆ˜ì… ë¬¼ê°€ ë° ë¬¼ê°€ìƒìŠ¹ ì••ë ¥ ê°€ì¤‘ ì˜ˆìƒ.\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ“Š 2. **ì›í™” ì•½ì„¸ì˜ ì£¼ìš” ì›ì¸**\n",
      "| ìš”ì¸ | ì„¤ëª… |\n",
      "|------|------|\n",
      "| **ê¸ˆë¦¬ ì°¨ì´** | ë¯¸êµ­ 10ë…„ë¬¼ êµ­ì±„ê¸ˆë¦¬ 4.2% vs í•œêµ­ 10ë…„ë¬¼ 3.3% â†’ **ì°¨ì´ 0.9%p**ë¡œ ì™¸êµ­ì¸ ìê¸ˆ ì´íƒˆ ìœ ë°œ |\n",
      "| **ìˆ˜ì¶œ ë‘”í™”** | ì¤‘êµ­ ê²½ê¸° ë‘”í™” + ë°˜ë„ì²´ ê°€ê²© í•˜ë½ â†’ í•œêµ­ ìˆ˜ì¶œ ê°ì†Œ â†’ ë‹¬ëŸ¬ ìˆ˜ê¸‰ ì•…í™” |\n",
      "| **ì—ë„ˆì§€ ê°€ê²©** | WTI ìœ ê°€ ë°°ëŸ´ë‹¹ $80+ â†’ ì—ë„ˆì§€ ìˆ˜ì… ì¦ê°€ â†’ ë‹¬ëŸ¬ ìˆ˜ìš” ì¦ê°€ |\n",
      "| **ì •ì¹˜ì  ë¶ˆí™•ì‹¤ì„±** | ë‚´ë…„ 4ì›” ì´ì„  ì•ë‘ê³  ì •ì±… ë¶ˆí™•ì‹¤ì„± â†‘ â†’ ì™¸êµ­ì¸ ìê¸ˆ íšŒí”¼ ì‹¬ë¦¬ |\n",
      "| **ì—”ìºë¦¬ì§€** | ì¼ë³¸ ì—”í™”ë„ ì•½ì„¸(USD/JPY 159+) â†’ ì•„ì‹œì•„ í†µí™” ì „ë°˜ ì•½ì„¸ â†’ ì›í™”ë„ ì—°ì‡„ í•˜ë½ |\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ“ˆ 3. **í–¥í›„ ì „ë§ (3ê°œì›” ë‚´)**\n",
      "| ì‹œë‚˜ë¦¬ì˜¤ | í™˜ìœ¨ ë²”ìœ„ | ê°€ëŠ¥ì„± | ì„¤ëª… |\n",
      "|----------|------------|--------|------|\n",
      "| **ë² ì´ìŠ¤** | 1,370~1,410ì› | 50% | ë¯¸êµ­ 1~2íšŒ ì¶”ê°€ ì¸ìƒ, í•œêµ­ì€ ë™ê²° â†’ ê¸ˆë¦¬ì°¨ ìœ ì§€ |\n",
      "| **ìƒìŠ¹** | 1,420~1,460ì› | 30% | ì¤‘êµ­ ê²½ê¸° ì¶”ê°€ ë‘”í™” + ìœ ê°€ ì¬ìƒìŠ¹ â†’ ë‹¬ëŸ¬ ìˆ˜ìš” â†‘ |\n",
      "| **í•˜ë½** | 1,300~1,340ì› | 20% | í•œêµ­ ê²½ì œì§€í‘œ ê°œì„ (ìˆ˜ì¶œ íšŒë³µ) + ë¯¸êµ­ ê¸ˆë¦¬ ì¸í•˜ ì‹œì‚¬ |\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ’¡ 4. **ì‹¤ë¬¼ ê²½ì œ/ê°œì¸ì—ê²Œ ë¯¸ì¹˜ëŠ” ì˜í–¥**\n",
      "| ì£¼ì²´ | ê¸ì •ì  ì˜í–¥ | ë¶€ì •ì  ì˜í–¥ |\n",
      "|------|--------------|--------------|\n",
      "| **ìˆ˜ì¶œê¸°ì—…** | í™˜ìœ¨ ì´ìµ â†‘ (ìë™ì°¨Â·ì¡°ì„ Â·í™”í•™) | ì›ìì¬ ìˆ˜ì…ë¹„ â†‘ |\n",
      "| **ìœ í•™ìƒ/í•´ì™¸ì—¬í–‰ê°** | ì—†ìŒ | ì›í™” ê°€ì¹˜ â†“ â†’ ë¹„ìš© â†‘ (ì•½ 9% ì¦ê°€) |\n",
      "| **ìˆ˜ì… ê¸°ì—…** | ì—†ìŒ | ë¬¼ê°€ ìƒìŠ¹ â†’ ì†Œë¹„ ìœ„ì¶• |\n",
      "| **ê°€ê³„** | ì—†ìŒ | í•´ì™¸ ì§êµ¬Â·ì—¬í–‰ë¹„ â†‘, ë¬¼ê°€ ìƒìŠ¹ ì••ë ¥ |\n",
      "\n",
      "---\n",
      "\n",
      "### âœ… 5. **ì‹¤ì „ ëŒ€ì‘ ì „ëµ**\n",
      "- **í™˜ì „ íƒ€ì´ë°**: 1,400ì› ê·¼ì ‘ ì‹œ **ë¶„í•  í™˜ì „** ê³ ë ¤ (1/3ì”©)\n",
      "- **ì™¸í™” ì˜ˆê¸ˆ**: **ë‹¬ëŸ¬ ì˜ˆê¸ˆ 3~6ê°œì›”ë¬¼** í™œìš© (ì—° 4%ëŒ€)\n",
      "- **ì£¼ì‹ íˆ¬ì**: **ìˆ˜ì¶œì£¼** ìš°ì„  (í˜„ëŒ€ì°¨Â·ì‚¼ì„±ì „ìÂ·POSCO), **ë‚´ìˆ˜ì£¼**ëŠ” ë‹¨ê¸° íšŒí”¼\n",
      "- **ì†Œë¹„ ì „ëµ**: **í•´ì™¸ ì§êµ¬Â·ì—¬í–‰**ì€ í™˜ìœ¨ ì•ˆì • ì‹œ(1,350ì› ì´í•˜)ë¡œ ì—°ê¸°\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ“Œ ìš”ì•½\n",
      "> **â€œ1,386ì›ì€ ê³ í™˜ìœ¨ì´ì§€ë§Œ, ì•„ì§ ì •ì ì€ ì•„ë‹ˆë‹¤. 1,400ì› ëŒíŒŒ ê°€ëŠ¥ì„±ì´ ë†’ìœ¼ë©°, ìˆ˜ì¶œ íšŒë³µì´ë‚˜ ë¯¸êµ­ ê¸ˆë¦¬ ì¸í•˜ ì‹œê·¸ë„ì´ ë‚˜ì˜¤ê¸° ì „ê¹Œì§€ ì›í™” ì•½ì„¸ëŠ” ì§€ì†ë  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤.â€**\n",
      "\n",
      "í•„ìš”í•˜ì‹œë©´ **ì—”í™”Â·ìœ„ì•ˆí™”Â·ìœ ë¡œ ëŒ€ë¹„ ì›í™” êµì°¨ í™˜ìœ¨**ì´ë‚˜ **ê°œì¸ ë§ì¶¤í˜• í™˜ì „ ì „ëµ**ë„ ì•Œë ¤ë“œë¦´ê²Œìš”.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ì‹¤ì‹œê°„ í™˜ìœ¨ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1ë‹¬ëŸ¬ = {data['rates']['KRW']}ì›\"\n",
    "\n",
    "# Partial Prompt í™œìš©\n",
    "prompt = PromptTemplate(\n",
    "    template=\"í˜„ì¬ {info} ê¸°ì¤€ìœ¼ë¡œ í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. ì´ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.\",\n",
    "    input_variables=[],  # ì‚¬ìš©ì ì…ë ¥ ì—†ìŒ\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # APIì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„° ìë™ ë°˜ì˜\n",
    ")\n",
    "\n",
    "# LLM ëª¨ë¸ ì„¤ì •\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "# ëª¨ë¸ì— í”„ë¡¬í”„íŠ¸ ì „ë‹¬ ë° ì‘ë‹µ ë°›ê¸°\n",
    "response = llm.invoke(prompt.format())\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\" í”„ë¡¬í”„íŠ¸:\", prompt.format())\n",
    "print(\" ëª¨ë¸ ì‘ë‹µ:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
