{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain!!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello LangChain!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_Z\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "#load_dotenv(dotenv_path='.env')\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt + llm + output \n",
    "\n",
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "System: ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.\n",
      "Human: íŒŒì´ì¬ì€ ë¬´ì—‡ì¸ê°€ìš”? ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\n"
     ]
    }
   ],
   "source": [
    "prompt_text = prompt.format(input=\"íŒŒì´ì¬ì€ ë¬´ì—‡ì¸ê°€ìš”? ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\")\n",
    "print(type(prompt_text))\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n",
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000021A6EF568A0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000021A706A3CB0> root_client=<openai.OpenAI object at 0x0000021A703E0950> root_async_client=<openai.AsyncOpenAI object at 0x0000021A704631A0> model_name='openai/gpt-oss-120b' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "#llm = ChatOpenAI(api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# Groq APIë¥¼ ì‚¬ìš©í•˜ëŠ” ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(type(llm))\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "ì‘ë‹µ: ## íŒŒì´ì¬(Python)ì´ë€?\n",
      "\n",
      "íŒŒì´ì¬ì€ **ê³ ìˆ˜ì¤€(highâ€‘level) ì¸í„°í”„ë¦¬í„° ì–¸ì–´**ì´ë©°, **ë™ì  íƒ€ì´í•‘(dynamic typing)**ê³¼ **ìë™ ë©”ëª¨ë¦¬ ê´€ë¦¬(garbage collection)**ë¥¼ ì œê³µí•˜ëŠ” **ë²”ìš© í”„ë¡œê·¸ë˜ë° ì–¸ì–´**ì…ë‹ˆë‹¤. 1991ë…„ ë„¤ëœë€ë“œì˜ ê·€ë„ ë°˜ ë¡œì„¬(Guido van Rossum)ì´ ì²˜ìŒ ë°œí‘œí–ˆìœ¼ë©°, í˜„ì¬ëŠ” ì „ ì„¸ê³„ ê°œë°œì ì»¤ë®¤ë‹ˆí‹°ì™€ ê¸°ì—…ì—ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ì–¸ì–´ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.  \n",
      "\n",
      "ì•„ë˜ì—ì„œëŠ” íŒŒì´ì¬ì˜ **ì—­ì‚¬Â·íŠ¹ì§•Â·êµ¬ì¡°Â·ì£¼ìš” í™œìš© ë¶„ì•¼Â·ìƒíƒœê³„**ë¥¼ ìƒì„¸íˆ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. íŒŒì´ì¬ì˜ ì—­ì‚¬ì™€ ë°œì „\n",
      "\n",
      "| ì—°ë„ | ì£¼ìš” ì‚¬ê±´ |\n",
      "|------|-----------|\n",
      "| **1980ë…„ëŒ€ í›„ë°˜** | ê·€ë„ ë°˜ ë¡œì„¬ì´ â€œABCâ€ ì–¸ì–´ì˜ ê°œì„ íŒì„ êµ¬ìƒ. |\n",
      "| **1991ë…„** | íŒŒì´ì¬ 0.9.0 ê³µê°œ (ìœ ë‹‰ìŠ¤, ìœˆë„ìš°, ë§¤í¬ë¡œ ì–¸ì–´). |\n",
      "| **1994ë…„** | íŒŒì´ì¬ 1.0 ë°œí‘œ â€“ ëª¨ë“ˆ, ì˜ˆì™¸ ì²˜ë¦¬, í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë° ìš”ì†Œ ì¶”ê°€. |\n",
      "| **2000ë…„** | íŒŒì´ì¬ 2.0 ì¶œì‹œ â€“ ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜, ê°€ë¹„ì§€ ì»¬ë ‰ì…˜, ìœ ë‹ˆì½”ë“œ ì§€ì›. |\n",
      "| **2008ë…„** | íŒŒì´ì¬ 3.0 (Python 3000) ë°œí‘œ â€“ ë¬¸ìì—´/ë°”ì´íŠ¸ êµ¬ë¶„, `print` í•¨ìˆ˜í™” ë“± ë¹„í˜¸í™˜ì  ë³€í™”. |\n",
      "| **2020ë…„** | íŒŒì´ì¬ 3.9, 3.10, 3.11 ë“± ìµœì‹  ë²„ì „ì—ì„œ ì„±ëŠ¥ ê°œì„ (íŒ¨í„´ ë§¤ì¹­, JIT-like ìµœì í™”) ë° ìƒˆë¡œìš´ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€. |\n",
      "| **2023ë…„** | íŒŒì´ì¬ 3.12 ë°œí‘œ â€“ íŒŒì‹± ì†ë„ 2ë°° ì´ìƒ í–¥ìƒ, ìƒˆë¡œìš´ `tomllib` ë“±. |\n",
      "| **2025ë…„ í˜„ì¬** | íŒŒì´ì¬ 3.13ì´ ë² íƒ€ ë‹¨ê³„ì— ìˆìœ¼ë©°, **CPython**(C êµ¬í˜„)ê³¼ **PyPy**(JIT êµ¬í˜„), **MicroPython**, **RustPython** ë“± ë‹¤ì–‘í•œ êµ¬í˜„ì²´ê°€ í™œë°œíˆ ìœ ì§€Â·ë³´ìˆ˜ ì¤‘. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. íŒŒì´ì¬ì˜ í•µì‹¬ íŠ¹ì§•\n",
      "\n",
      "| íŠ¹ì§• | ì„¤ëª… | ì¥ì  |\n",
      "|------|------|------|\n",
      "| **ì½ê¸° ì‰¬ìš´ ë¬¸ë²•** | ë“¤ì—¬ì“°ê¸°(Indentation)ë¡œ ë¸”ë¡ì„ êµ¬ë¶„í•˜ê³ , ë¶ˆí•„ìš”í•œ êµ¬ë¶„ìë¥¼ ìµœì†Œí™”. | ì½”ë“œ ê°€ë…ì„±Â·ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ |\n",
      "| **ë™ì  íƒ€ì´í•‘** | ë³€ìˆ˜ ì„ ì–¸ ì‹œ íƒ€ì…ì„ ëª…ì‹œí•˜ì§€ ì•Šìœ¼ë©°, ëŸ°íƒ€ì„ì— íƒ€ì…ì´ ê²°ì •. | ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘, ì ì€ ë³´ì¼ëŸ¬í”Œë ˆì´íŠ¸ |\n",
      "| **ì¸í„°í”„ë¦¬í„° ì–¸ì–´** | ì†ŒìŠ¤ ì½”ë“œë¥¼ ë°”ë¡œ ì‹¤í–‰(ì¸í„°í”„ë¦¬í„°)í•˜ê±°ë‚˜ ë°”ì´íŠ¸ì½”ë“œ(.pyc)ë¡œ ì»´íŒŒì¼ í›„ ì‹¤í–‰. | í”Œë«í¼ ë…ë¦½ì„±, REPL(ëŒ€í™”í˜• ì‰˜) í™œìš© ê°€ëŠ¥ |\n",
      "| **í’ë¶€í•œ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬** | `os`, `json`, `datetime`, `http`, `sqlite3` ë“± 200ì—¬ ê°œ ëª¨ë“ˆ ì œê³µ. | ì™¸ë¶€ íŒ¨í‚¤ì§€ ì—†ì´ë„ ë‹¤ì–‘í•œ ì‘ì—… ìˆ˜í–‰ ê°€ëŠ¥ |\n",
      "| **í™•ì¥ì„±** | C/C++(CPython), Java(Jython), .NET(IronPython) ë“±ìœ¼ë¡œ êµ¬í˜„ëœ ì¸í„°í”„ë¦¬í„°ì™€ ì—°ë™ ê°€ëŠ¥. | ì„±ëŠ¥-critical ë¶€ë¶„ì„ Cë¡œ êµ¬í˜„í•˜ê±°ë‚˜ ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ í†µí•© ìš©ì´ |\n",
      "| **ë©€í‹°íŒ¨ëŸ¬ë‹¤ì„** | ì ˆì°¨ì Â·ê°ì²´ì§€í–¥Â·í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë° ì§€ì›. | ë¬¸ì œì— ë§ëŠ” ìŠ¤íƒ€ì¼ ì„ íƒ ê°€ëŠ¥ |\n",
      "| **ê°€ë¹„ì§€ ì»¬ë ‰ì…˜** | ìë™ ë©”ëª¨ë¦¬ ê´€ë¦¬(ì°¸ì¡° ì¹´ìš´íŒ… + ì‚¬ì´í´ íƒì§€). | ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ìœ„í—˜ ê°ì†Œ |\n",
      "| **ëŒ€ê·œëª¨ ì»¤ë®¤ë‹ˆí‹°ì™€ ì—ì½”ì‹œìŠ¤í…œ** | PyPI(Python Package Index)ì— 400,000+ íŒ¨í‚¤ì§€ ì¡´ì¬. | ê±°ì˜ ëª¨ë“  ë¶„ì•¼(ì›¹, ê³¼í•™, AI, ìë™í™” ë“±)ì—ì„œ ì†”ë£¨ì…˜ ì°¾ê¸° ì‰¬ì›€ |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. íŒŒì´ì¬ ì–¸ì–´ êµ¬ì¡°ì™€ ê¸°ë³¸ ë¬¸ë²•\n",
      "\n",
      "### 3â€‘1. ê¸°ë³¸ ë°ì´í„° íƒ€ì…\n",
      "\n",
      "| íƒ€ì… | ë¦¬í„°ëŸ´ ì˜ˆì‹œ | íŠ¹ì§• |\n",
      "|------|------------|------|\n",
      "| `int` | `42`, `-7` | ë¬´ì œí•œ ì •ë°€ë„ ì •ìˆ˜ |\n",
      "| `float` | `3.14`, `-0.001` | IEEE 754 ë°°ì •ë°€ë„ ë¶€ë™ì†Œìˆ˜ì  |\n",
      "| `bool` | `True`, `False` | ë…¼ë¦¬ê°’ |\n",
      "| `str` | `'hello'`, `\"world\"` | ìœ ë‹ˆì½”ë“œ ë¬¸ìì—´ (Pythonâ€¯3) |\n",
      "| `list` | `[1, 2, 3]` | ê°€ë³€ ìˆœì„œ ì»¬ë ‰ì…˜ |\n",
      "| `tuple` | `(1, 2, 3)` | ë¶ˆë³€ ìˆœì„œ ì»¬ë ‰ì…˜ |\n",
      "| `set` | `{1, 2, 3}` | ì¤‘ë³µ ì—†ëŠ” ë¬´ìˆœì„œ ì»¬ë ‰ì…˜ |\n",
      "| `dict` | `{'a': 1, 'b': 2}` | í‚¤â€‘ê°’ ë§¤í•‘, í•´ì‹œ ê¸°ë°˜ |\n",
      "\n",
      "### 3â€‘2. ì œì–´ íë¦„\n",
      "\n",
      "```python\n",
      "# ì¡°ê±´ë¬¸\n",
      "if x > 0:\n",
      "    print(\"ì–‘ìˆ˜\")\n",
      "elif x == 0:\n",
      "    print(\"0\")\n",
      "else:\n",
      "    print(\"ìŒìˆ˜\")\n",
      "\n",
      "# ë°˜ë³µë¬¸\n",
      "for i in range(5):\n",
      "    print(i)          # 0~4 ì¶œë ¥\n",
      "\n",
      "while condition:\n",
      "    # ë°˜ë³µ ìˆ˜í–‰\n",
      "    ...\n",
      "\n",
      "# ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜\n",
      "squares = [x*x for x in range(10) if x % 2 == 0]\n",
      "```\n",
      "\n",
      "### 3â€‘3. í•¨ìˆ˜ì™€ ëŒë‹¤\n",
      "\n",
      "```python\n",
      "def fib(n: int) -> int:\n",
      "    \"\"\"në²ˆì§¸ í”¼ë³´ë‚˜ì¹˜ ìˆ˜ ë°˜í™˜ (ì¬ê·€)\"\"\"\n",
      "    if n <= 1:\n",
      "        return n\n",
      "    return fib(n-1) + fib(n-2)\n",
      "\n",
      "# ëŒë‹¤ì‹ (ìµëª… í•¨ìˆ˜)\n",
      "add = lambda a, b: a + b\n",
      "```\n",
      "\n",
      "### 3â€‘4. í´ë˜ìŠ¤ì™€ ê°ì²´ì§€í–¥\n",
      "\n",
      "```python\n",
      "class Animal:\n",
      "    def __init__(self, name: str):\n",
      "        self.name = name\n",
      "\n",
      "    def speak(self):\n",
      "        raise NotImplementedError\n",
      "\n",
      "class Dog(Animal):\n",
      "    def speak(self):\n",
      "        return \"ë©ë©\"\n",
      "\n",
      "class Cat(Animal):\n",
      "    def speak(self):\n",
      "        return \"ì•¼ì˜¹\"\n",
      "\n",
      "pets = [Dog(\"ë°”ë‘‘ì´\"), Cat(\"ë‚˜ë¹„\")]\n",
      "for p in pets:\n",
      "    print(p.name, \":\", p.speak())\n",
      "```\n",
      "\n",
      "### 3â€‘5. ëª¨ë“ˆÂ·íŒ¨í‚¤ì§€Â·ê°€ìƒ í™˜ê²½\n",
      "\n",
      "```bash\n",
      "# íŒ¨í‚¤ì§€ ì„¤ì¹˜ (pip)\n",
      "pip install requests\n",
      "\n",
      "# ê°€ìƒ í™˜ê²½ ìƒì„±Â·í™œì„±í™”\n",
      "python -m venv .venv\n",
      "source .venv/bin/activate   # Linux/macOS\n",
      ".\\.venv\\Scripts\\activate    # Windows\n",
      "```\n",
      "\n",
      "```python\n",
      "# mypkg/__init__.py\n",
      "def hello():\n",
      "    print(\"Hello from my package!\")\n",
      "\n",
      "# ì‚¬ìš©\n",
      "import mypkg\n",
      "mypkg.hello()\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 4. íŒŒì´ì¬ ì‹¤í–‰ ë°©ì‹\n",
      "\n",
      "1. **ì†ŒìŠ¤ íŒŒì¼(.py)** â†’ íŒŒì´ì¬ ì¸í„°í”„ë¦¬í„°ê°€ **íŒŒì‹± â†’ AST(Abstract Syntax Tree) ìƒì„± â†’ ë°”ì´íŠ¸ì½”ë“œ ì»´íŒŒì¼**  \n",
      "2. ë°”ì´íŠ¸ì½”ë“œ(.pyc)ëŠ” **CPython ê°€ìƒ ë¨¸ì‹ **ì— ì˜í•´ **ìŠ¤íƒ ê¸°ë°˜ ëª…ë ¹ì–´**ë¡œ ì‹¤í–‰.  \n",
      "3. **JIT êµ¬í˜„ì²´(PyPy)**ëŠ” ë°”ì´íŠ¸ì½”ë“œë¥¼ ëŸ°íƒ€ì„ì— **ë„¤ì´í‹°ë¸Œ ë¨¸ì‹  ì½”ë“œ**ë¡œ ë³€í™˜í•´ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚´.  \n",
      "\n",
      "> **í•µì‹¬ í¬ì¸íŠ¸**: íŒŒì´ì¬ì€ **ì»´íŒŒì¼ ì–¸ì–´**ì™€ **ì¸í„°í”„ë¦¬í„° ì–¸ì–´**ì˜ ì¤‘ê°„ í˜•íƒœ(ë°”ì´íŠ¸ì½”ë“œ ê¸°ë°˜)ì´ë©°, ì´ëŠ” **í”Œë«í¼ ë…ë¦½ì„±**ê³¼ **ë¹ ë¥¸ ê°œë°œ ì†ë„**ë¥¼ ë™ì‹œì— ì œê³µí•œë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. ì£¼ìš” í™œìš© ë¶„ì•¼\n",
      "\n",
      "| ë¶„ì•¼ | ëŒ€í‘œ ë¼ì´ë¸ŒëŸ¬ë¦¬Â·í”„ë ˆì„ì›Œí¬ | ì‚¬ìš© ì‚¬ë¡€ |\n",
      "|------|--------------------------|-----------|\n",
      "| **ì›¹ ê°œë°œ** | Django, Flask, FastAPI, Tornado | ì›¹ì‚¬ì´íŠ¸Â·REST APIÂ·ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ |\n",
      "| **ë°ì´í„° ê³¼í•™Â·ë¶„ì„** | NumPy, pandas, SciPy, Dask | ë°ì´í„° ì „ì²˜ë¦¬Â·í†µê³„Â·ì‹œê³„ì—´ ë¶„ì„ |\n",
      "| **ë¨¸ì‹ ëŸ¬ë‹Â·ë”¥ëŸ¬ë‹** | scikit-learn, TensorFlow, PyTorch, Keras | ëª¨ë¸ í•™ìŠµÂ·ì˜ˆì¸¡Â·ì»´í“¨í„° ë¹„ì „Â·ìì—°ì–´ ì²˜ë¦¬ |\n",
      "| **ìë™í™”Â·ìŠ¤í¬ë¦½íŒ…** | `os`, `subprocess`, `shutil`, `pyautogui` | íŒŒì¼Â·ì‹œìŠ¤í…œ ê´€ë¦¬Â·í…ŒìŠ¤íŠ¸ ìë™í™”Â·RPA |\n",
      "| **ì‹œìŠ¤í…œ ê´€ë¦¬Â·DevOps** | Ansible, SaltStack, Fabric | ì¸í”„ë¼ í”„ë¡œë¹„ì €ë‹Â·ë°°í¬ íŒŒì´í”„ë¼ì¸ |\n",
      "| **ê³¼í•™Â·ê³µí•™** | SymPy, matplotlib, Plotly, Jupyter | ìˆ˜ì‹ ê¸°í˜¸ ì—°ì‚°Â·ì‹œë®¬ë ˆì´ì…˜Â·ì‹œê°í™” |\n",
      "| **ê²Œì„Â·ë©€í‹°ë¯¸ë””ì–´** | Pygame, Panda3D, Kivy | 2D/3D ê²Œì„Â·ì¸í„°ë™í‹°ë¸Œ ì•± |\n",
      "| **ì„ë² ë””ë“œÂ·IoT** | MicroPython, CircuitPython | ë§ˆì´í¬ë¡œì»¨íŠ¸ë¡¤ëŸ¬(ESP32, Raspberry Pi Pico) í”„ë¡œê·¸ë˜ë° |\n",
      "| **êµìœ¡** | Turtle, IDLE, Jupyter Notebook | í”„ë¡œê·¸ë˜ë° ì…ë¬¸Â·ì½”ë”© êµìœ¡ |\n",
      "\n",
      "---\n",
      "\n",
      "## 6. íŒŒì´ì¬ ìƒíƒœê³„ì™€ ë„êµ¬\n",
      "\n",
      "| êµ¬ë¶„ | ë„êµ¬Â·í”Œë«í¼ | ì„¤ëª… |\n",
      "|------|------------|------|\n",
      "| **íŒ¨í‚¤ì§€ ê´€ë¦¬** | `pip`, `conda` | PyPIì™€ Anaconda ë ˆí¬ì§€í„°ë¦¬ì—ì„œ íŒ¨í‚¤ì§€ ì„¤ì¹˜Â·ê´€ë¦¬ |\n",
      "| **ê°€ìƒ í™˜ê²½** | `venv`, `virtualenv`, `conda env` | í”„ë¡œì íŠ¸ë³„ ì˜ì¡´ì„± ê²©ë¦¬ |\n",
      "| **IDE/í¸ì§‘ê¸°** | PyCharm, VS Code, Spyder, JupyterLab, Thonny | ì •ì  ë¶„ì„Â·ë””ë²„ê¹…Â·ìë™ ì™„ì„± ì§€ì› |\n",
      "| **í…ŒìŠ¤íŒ…** | `unittest`, `pytest`, `nose2` | ë‹¨ìœ„Â·í†µí•©Â·ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ |\n",
      "| **í˜•ì‹ ê²€ì‚¬** | `mypy`, `pyright`, `pylint`, `flake8` | ì •ì  íƒ€ì… ì²´í¬Â·ì½”ë“œ ìŠ¤íƒ€ì¼ ê²€ì‚¬ |\n",
      "| **ë°°í¬** | `setuptools`, `wheel`, `twine`, `poetry` | íŒ¨í‚¤ì§€ ë¹Œë“œÂ·ë°°í¬Â·ë²„ì „ ê´€ë¦¬ |\n",
      "| **CI/CD** | GitHub Actions, GitLab CI, Travis CI, CircleCI | ìë™ ë¹Œë“œÂ·í…ŒìŠ¤íŠ¸Â·ë°°í¬ íŒŒì´í”„ë¼ì¸ |\n",
      "| **ë¬¸ì„œí™”** | Sphinx, MkDocs, pdoc | API ë¬¸ì„œÂ·ì‚¬ìš©ì ê°€ì´ë“œ ìë™ ìƒì„± |\n",
      "\n",
      "---\n",
      "\n",
      "## 7. ì„±ëŠ¥ ìµœì í™”ì™€ í•œê³„\n",
      "\n",
      "| ìƒí™© | ìµœì í™” ë°©ë²• | ë¹„ê³  |\n",
      "|------|------------|------|\n",
      "| **CPUâ€‘bound ì—°ì‚°** | C í™•ì¥ ëª¨ë“ˆ (`Cython`, `Numba`), `multiprocessing`(í”„ë¡œì„¸ìŠ¤ ê¸°ë°˜ ë³‘ë ¬) | GIL(Global Interpreter Lock) íšŒí”¼ |\n",
      "| **I/Oâ€‘bound ì‘ì—…** | `asyncio`, `aiohttp`, `trio` ê°™ì€ ë¹„ë™ê¸° í”„ë ˆì„ì›Œí¬ | ì´ë²¤íŠ¸ ë£¨í”„ ê¸°ë°˜ ë™ì‹œì„± |\n",
      "| **ëŒ€ê·œëª¨ ë°ì´í„°** | `Dask`, `PySpark`, `Modin` ë“± ë¶„ì‚° ë°ì´í„°í”„ë ˆì„ | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì†Œí™” |\n",
      "| **ì‹¤í–‰ ì†ë„** | `PyPy`(JIT), `CPython` ìµœì‹  ë²„ì „(3.11+), `pyston` ë“± | ëŒ€ë¶€ë¶„ì˜ ê²½ìš° 2~4ë°° ê°€ì† |\n",
      "| **ë°°í¬ í¬ê¸°** | `pyinstaller`, `cx_Freeze`, `briefcase` ë“±ìœ¼ë¡œ ë…ë¦½ ì‹¤í–‰ íŒŒì¼ ìƒì„± | ì¢…ì†ì„± í¬í•¨ ë°°í¬ ìš©ì´ |\n",
      "\n",
      "> **ì£¼ì˜**: íŒŒì´ì¬ì€ **ê°€ë…ì„±Â·ìƒì‚°ì„±**ì„ ì¤‘ì‹œí•˜ëŠ” ì–¸ì–´ì´ë©°, **ì‹¤ì‹œê°„Â·ì´ˆì €ì§€ì—° ì‹œìŠ¤í…œ(ì˜ˆ: ê³ ì£¼íŒŒ íŠ¸ë ˆì´ë”©, ì»¤ë„ ëª¨ë“ˆ)**ì—ëŠ” C/C++Â·Rust ë“± ì €ìˆ˜ì¤€ ì–¸ì–´ê°€ ë” ì í•©í•©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 8. íŒŒì´ì¬ í•™ìŠµ ë¡œë“œë§µ (ì´ˆê¸‰ â†’ ê³ ê¸‰)\n",
      "\n",
      "1. **ê¸°ì´ˆ**  \n",
      "   - ë³€ìˆ˜Â·ìë£Œí˜•Â·ì—°ì‚°ì  \n",
      "   - ì œì–´ë¬¸Â·í•¨ìˆ˜Â·ì˜ˆì™¸ ì²˜ë¦¬  \n",
      "   - ê¸°ë³¸ ì…ì¶œë ¥Â·íŒŒì¼ I/O  \n",
      "\n",
      "2. **ì‹¬í™”**  \n",
      "   - ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë°(OOP)  \n",
      "   - ëª¨ë“ˆÂ·íŒ¨í‚¤ì§€Â·ê°€ìƒ í™˜ê²½ ê´€ë¦¬  \n",
      "   - í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš© (`datetime`, `pathlib`, `logging` ë“±)  \n",
      "\n",
      "3. **ì „ë¬¸ ë¶„ì•¼**  \n",
      "   - **ì›¹**: Flask â†’ Django â†’ FastAPI (ë¹„ë™ê¸°)  \n",
      "   - **ë°ì´í„°**: NumPy â†’ pandas â†’ matplotlib/Seaborn â†’ scikit-learn  \n",
      "   - **AI**: TensorFlow/Keras â†’ PyTorch â†’ Hugging Face Transformers  \n",
      "   - **ìë™í™”**: `requests`, `beautifulsoup4`, `selenium`  \n",
      "\n",
      "4. **í’ˆì§ˆÂ·ìš´ì˜**  \n",
      "   - í…ŒìŠ¤íŠ¸(`pytest`), íƒ€ì… íŒíŠ¸(`mypy`), ì½”ë“œ ìŠ¤íƒ€ì¼(`black`, `flake8`)  \n",
      "   - CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•  \n",
      "   - ì»¨í…Œì´ë„ˆí™”(Docker)Â·í´ë¼ìš°ë“œ ë°°í¬(AWS Lambda, GCP Cloud Functions)  \n",
      "\n",
      "5. **ê³ ê¸‰ ì£¼ì œ**  \n",
      "   - ë©”íƒ€í”„ë¡œê·¸ë˜ë°(ë°ì½”ë ˆì´í„°Â·í´ë˜ìŠ¤ ë©”íƒ€)  \n",
      "   - C í™•ì¥Â·CythonÂ·Numba  \n",
      "   - ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°(`asyncio`, `trio`)  \n",
      "   - ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§(`cProfile`, `line_profiler`)  \n",
      "\n",
      "---\n",
      "\n",
      "## 9. íŒŒì´ì¬ì„ ì„ íƒí•´ì•¼ í•˜ëŠ” ì´ìœ  (ìš”ì•½)\n",
      "\n",
      "| ì¥ì  | êµ¬ì²´ì ì¸ ì´ìœ  |\n",
      "|------|----------------|\n",
      "| **ê°€ë…ì„±** | ëª…í™•í•œ ë¬¸ë²•Â·ì¼ê´€ëœ ìŠ¤íƒ€ì¼ â†’ íŒ€ í˜‘ì—… íš¨ìœ¨ ìƒìŠ¹ |\n",
      "| **ìƒì‚°ì„±** | ì§§ì€ ì½”ë“œÂ·í’ë¶€í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ â†’ í”„ë¡œí† íƒ€ì… ì œì‘ ì†ë„ ë¹ ë¦„ |\n",
      "| **ë‹¤ì–‘í•œ ë„ë©”ì¸** | ì›¹Â·ë°ìŠ¤í¬í†±Â·ë°ì´í„°Â·AIÂ·IoT ë“± ê±°ì˜ ëª¨ë“  ë¶„ì•¼ ì»¤ë²„ |\n",
      "| **í™œë°œí•œ ì»¤ë®¤ë‹ˆí‹°** | ì§ˆë¬¸Â·ë‹µë³€Â·íŒ¨í‚¤ì§€Â·ì»¨í¼ëŸ°ìŠ¤ê°€ í’ë¶€ â†’ ë¬¸ì œ í•´ê²°ì´ ì‰¬ì›€ |\n",
      "| **í”Œë«í¼ ë…ë¦½ì„±** | Windows, macOS, Linux, Android, iOS(ì˜ˆ: Kivy) ë“± ì–´ë””ì„œë“  ì‹¤í–‰ |\n",
      "| **ì˜¤í”ˆì†ŒìŠ¤** | ë¬´ë£ŒÂ·ì˜¤í”ˆì†ŒìŠ¤ â†’ ë¹„ìš© ì ˆê°Â·ì»¤ìŠ¤í„°ë§ˆì´ì§• ììœ  |\n",
      "\n",
      "---\n",
      "\n",
      "## 10. ë§ˆë¬´ë¦¬ & ì°¸ê³  ìë£Œ\n",
      "\n",
      "- **ê³µì‹ ë¬¸ì„œ**: <https://docs.python.org/3/> (ì˜ë¬¸) / <https://docs.python.org/ko/3/> (í•œê¸€ ë²ˆì—­)  \n",
      "- **í•™ìŠµ ì‚¬ì´íŠ¸**:  \n",
      "  - Python ê³µì‹ íŠœí† ë¦¬ì–¼  \n",
      "  - Real Python (https://realpython.com)  \n",
      "  - Codecademy, Coursera, Udemy ë“±  \n",
      "- **í•µì‹¬ ì„œì **:  \n",
      "  - â€œíŒŒì´ì¬ ì½”ë”© ë„ì¥â€ â€“ ì´ˆê¸‰ ì…ë¬¸ììš©  \n",
      "  - â€œFluent Pythonâ€ â€“ ê³ ê¸‰ íŒŒì´ì¬ í…Œí¬ë‹‰  \n",
      "  - â€œEffective Pythonâ€ â€“ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ 90ê°€ì§€  \n",
      "- **ì»¤ë®¤ë‹ˆí‹°**:  \n",
      "  - Stack Overflow (íŒŒì´ì¬ íƒœê·¸)  \n",
      "  - Reddit r/Python, Discord íŒŒì´ì¬ ì„œë²„  \n",
      "  - êµ­ë‚´: íŒŒì´ì¬Â·ì½”ë”©Â·í”„ë¡œê·¸ë˜ë° ì¹´í˜, OKKY ë“±  \n",
      "\n",
      "> **í•œ ì¤„ ì •ë¦¬**: íŒŒì´ì¬ì€ **ì½ê¸° ì‰¬ìš´ ë¬¸ë²• + ë°©ëŒ€í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬**ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ë¹ ë¥´ê²Œ ë¬¸ì œë¥¼ í•´ê²°**í•  ìˆ˜ ìˆê²Œ í•´ ì£¼ëŠ” í˜„ëŒ€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì´ë©°, ì§€ì†ì ì¸ ì—…ë°ì´íŠ¸ì™€ í™œë°œí•œ ì»¤ë®¤ë‹ˆí‹° ë•ë¶„ì— ì•ìœ¼ë¡œë„ ì¤‘ìš”í•œ ìœ„ì¹˜ë¥¼ ìœ ì§€í•  ê²ƒì…ë‹ˆë‹¤.  \n",
      "\n",
      "ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(\"ì‘ë‹µ:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000021A6EF568A0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000021A706A3CB0>, root_client=<openai.OpenAI object at 0x0000021A703E0950>, root_async_client=<openai.AsyncOpenAI object at 0x0000021A704631A0>, model_name='openai/gpt-oss-120b', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input\":\"LangChainì€ ë¬´ì—‡ì¸ê°€ìš”?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "**LangChain(ë­ì²´ì¸)**ì€ **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)**ì„ **ì• í”Œë¦¬ì¼€ì´ì…˜ ìˆ˜ì¤€**ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ëŠ” **ì˜¤í”ˆì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬**ì…ë‹ˆë‹¤.  \n",
      "LLM ìì²´ëŠ” â€œí…ìŠ¤íŠ¸ë¥¼ ìƒì„±Â·ì˜ˆì¸¡â€í•˜ëŠ” ì—”ì§„ì— ë¶ˆê³¼í•˜ì§€ë§Œ, ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë³µí•©ì ì¸ ì‘ì—… íë¦„ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "| í•„ìš” ê¸°ëŠ¥ | LangChainì´ ì œê³µí•˜ëŠ” í•µì‹¬ ì»´í¬ë„ŒíŠ¸ |\n",
      "|----------|-----------------------------------|\n",
      "| **í”„ë¡¬í”„íŠ¸ ê´€ë¦¬** | `PromptTemplate`, `FewShotPromptTemplate` ë“±ìœ¼ë¡œ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì •ì˜Â·ì¡°í•© |\n",
      "| **ì²´ì¸(Chain)** | ì—¬ëŸ¬ LLM í˜¸ì¶œÂ·ì „ì²˜ë¦¬Â·í›„ì²˜ë¦¬ë¥¼ ìˆœì°¨Â·ì¡°ê±´ë¶€ë¡œ ì—°ê²° (ì˜ˆ: `LLMChain`, `SequentialChain`, `RouterChain`) |\n",
      "| **ì—ì´ì „íŠ¸(Agent)** | ëª©í‘œì— ë§ëŠ” ë„êµ¬(tool)ë¥¼ ë™ì ìœ¼ë¡œ ì„ íƒÂ·ì‹¤í–‰ (ì˜ˆ: `ZeroShotAgent`, `ReactAgent`) |\n",
      "| **ë©”ëª¨ë¦¬(Memory)** | ëŒ€í™”Â·ì‘ì—… ì´ë ¥ ë³´ê´€ (ì˜ˆ: `ConversationBufferMemory`, `VectorStoreRetrieverMemory`) |\n",
      "| **ë„êµ¬Â·í†µí•©** | ê²€ìƒ‰ ì—”ì§„, ë°ì´í„°ë² ì´ìŠ¤, íŒŒì¼ ì‹œìŠ¤í…œ, API ë“± ì™¸ë¶€ ì„œë¹„ìŠ¤ì™€ ì—°ê²° (ì˜ˆ: `Tool`, `Retriever`) |\n",
      "| **ë²¡í„° ìŠ¤í† ì–´** | ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰Â·ìœ ì‚¬ë„ ë§¤ì¹­ (FAISS, Pinecone, Weaviate ë“±) |\n",
      "| **ë°°í¬Â·ìš´ì˜** | `LangChainHub`(í”„ë¡¬í”„íŠ¸Â·ì²´ì¸ ê³µìœ ), `LangServe`(REST APIë¡œ ì‰½ê²Œ ë°°í¬) ë“± |\n",
      "\n",
      "---\n",
      "\n",
      "## 1. ì™œ LangChainì´ í•„ìš”í•œê°€?\n",
      "\n",
      "1. **LLMì„ ë‹¨ì¼ í˜¸ì¶œì´ ì•„ë‹Œ íŒŒì´í”„ë¼ì¸**ìœ¼ë¡œ ì‚¬ìš©í•˜ê³  ì‹¶ë‹¤.  \n",
      "2. **í”„ë¡¬í”„íŠ¸ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬Â·ë²„ì „ ê´€ë¦¬**í•˜ê³  ì‹¶ë‹¤.  \n",
      "3. **ì™¸ë¶€ ë°ì´í„°(ê²€ìƒ‰ ê²°ê³¼, DB, íŒŒì¼ ë“±)ì™€ ê²°í•©**í•œ ë³µí•© ì‘ì—…ì„ êµ¬í˜„í•˜ê³  ì‹¶ë‹¤.  \n",
      "4. **ëŒ€í™” íë¦„Â·ìƒíƒœ(ë©”ëª¨ë¦¬)**ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì—°ì†ì ì¸ ì§ˆë¬¸â€‘ì‘ë‹µì„ ì œê³µí•˜ê³  ì‹¶ë‹¤.  \n",
      "5. **ë‹¤ì–‘í•œ LLM ì œê³µì(OpenAI, Anthropic, Cohere, Llama, HuggingFace ë“±)**ë¥¼ ì¶”ìƒí™”ëœ ì¸í„°í˜ì´ìŠ¤ í•˜ë‚˜ë¡œ êµì²´í•˜ê³  ì‹¶ë‹¤.\n",
      "\n",
      "LangChainì€ ìœ„ ìš”êµ¬ë¥¼ **ì»´í¬ë„ŒíŠ¸ ë‹¨ìœ„ë¡œ ë¶„ë¦¬**í•˜ê³ , **PythonÂ·JavaScriptÂ·TypeScriptÂ·JavaÂ·Go ë“± ì—¬ëŸ¬ ì–¸ì–´**ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤. ê°€ì¥ í™œë°œíˆ ì‚¬ìš©ë˜ëŠ” ë²„ì „ì€ **Python**ì´ë©°, ê³µì‹ ë¬¸ì„œëŠ” <https://python.langchain.com> ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. ì£¼ìš” ê°œë…ê³¼ íë¦„\n",
      "\n",
      "### 2.1 PromptTemplate\n",
      "```python\n",
      "from langchain.prompts import PromptTemplate\n",
      "\n",
      "template = \"\"\"You are a helpful assistant.\n",
      "User: {question}\n",
      "Assistant:\"\"\"\n",
      "prompt = PromptTemplate.from_template(template)\n",
      "```\n",
      "- ë³€ìˆ˜(`{question}`)ë¥¼ ë™ì ìœ¼ë¡œ ì±„ì›Œì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "- `FewShotPromptTemplate`ì„ ì‚¬ìš©í•˜ë©´ ì˜ˆì‹œ(ìƒ˜í”Œ)ë„ ìë™ ì‚½ì… ê°€ëŠ¥.\n",
      "\n",
      "### 2.2 LLM & LLMChain\n",
      "```python\n",
      "from langchain.llms import OpenAI\n",
      "from langchain.chains import LLMChain\n",
      "\n",
      "llm = OpenAI(model=\"gpt-4o-mini\")\n",
      "chain = LLMChain(llm=llm, prompt=prompt)\n",
      "\n",
      "answer = chain.run({\"question\": \"í•œêµ­ì˜ ìˆ˜ë„ëŠ”?\"})\n",
      "```\n",
      "- `LLM` ê°ì²´ëŠ” ì‹¤ì œ ëª¨ë¸ í˜¸ì¶œì„ ë‹´ë‹¹í•˜ê³ , `LLMChain`ì€ í”„ë¡¬í”„íŠ¸ì™€ LLMì„ ë¬¶ì–´ í•œ ë²ˆì— ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
      "\n",
      "### 2.3 Retriever + VectorStore\n",
      "```python\n",
      "from langchain.vectorstores import FAISS\n",
      "from langchain.embeddings import OpenAIEmbeddings\n",
      "from langchain.retrievers import VectorStoreRetriever\n",
      "\n",
      "emb = OpenAIEmbeddings()\n",
      "docs = [\"ì„œìš¸ì€ í•œêµ­ì˜ ìˆ˜ë„ì´ë‹¤.\", \"ë¶€ì‚°ì€ í•œêµ­ì˜ ì œ2ë„ì‹œì´ë‹¤.\"]\n",
      "vectorstore = FAISS.from_texts(docs, emb)\n",
      "retriever = VectorStoreRetriever(vectorstore=vectorstore, k=2)\n",
      "```\n",
      "- ë¬¸ì„œë“¤ì„ ì„ë² ë”©í•´ ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥í•˜ê³ , ì§ˆì˜ì™€ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ `retriever`ê°€ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
      "- `RetrievalQAChain` ê°™ì€ ì²´ì¸ì— ì—°ê²°í•˜ë©´ â€œê²€ìƒ‰ + ë‹µë³€ ìƒì„±â€ íë¦„ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### 2.4 Agent\n",
      "```python\n",
      "from langchain.agents import initialize_agent, Tool\n",
      "from langchain.tools import DuckDuckGoSearchRun\n",
      "\n",
      "search = DuckDuckWebSearchRun()\n",
      "tools = [Tool(name=\"search\", func=search.run, description=\"Web search\")]\n",
      "agent = initialize_agent(tools, llm, agent_type=\"zero-shot-react-description\")\n",
      "agent.run(\"2024ë…„ í•œêµ­ì˜ ì¸êµ¬ëŠ” ì–¼ë§ˆì¸ê°€?\")\n",
      "```\n",
      "- ì—ì´ì „íŠ¸ëŠ” **ëª©í‘œ**ë¥¼ ë°›ì•„ì„œ **ì–´ë–¤ ë„êµ¬ë¥¼ ì–¸ì œ ì‚¬ìš©í• ì§€** ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.\n",
      "- `react`, `openai-functions`, `tool-calling` ë“± ë‹¤ì–‘í•œ ì „ëµì´ ì œê³µë©ë‹ˆë‹¤.\n",
      "\n",
      "### 2.5 Memory\n",
      "```python\n",
      "from langchain.memory import ConversationBufferMemory\n",
      "\n",
      "memory = ConversationBufferMemory()\n",
      "chat_chain = LLMChain(llm=llm, prompt=prompt, memory=memory)\n",
      "\n",
      "chat_chain.run({\"question\": \"ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ?\"})\n",
      "chat_chain.run({\"question\": \"ë‚´ê°€ ë°©ê¸ˆ ë¬¼ì–´ë³¸ ê±° ê¸°ì–µí•´?\"})\n",
      "```\n",
      "- ëŒ€í™” ê¸°ë¡ì„ ìë™ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ì— í¬í•¨í•´ ì—°ì†ì ì¸ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\n",
      "- `ConversationSummaryMemory`, `VectorStoreRetrieverMemory` ë“± ëª©ì ì— ë§ëŠ” ì—¬ëŸ¬ ë©”ëª¨ë¦¬ êµ¬í˜„ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€\n",
      "\n",
      "| ë¶„ì•¼ | êµ¬ì²´ì ì¸ ì˜ˆì‹œ |\n",
      "|------|--------------|\n",
      "| **ì±—ë´‡** | ê³ ê° ë¬¸ì˜ â†’ ê²€ìƒ‰Â·DB ì¡°íšŒ â†’ ë‹µë³€ ìƒì„± + ëŒ€í™” ë©”ëª¨ë¦¬ |\n",
      "| **ë¬¸ì„œ ìš”ì•½** | ëŒ€ìš©ëŸ‰ PDF/í…ìŠ¤íŠ¸ â†’ chunk â†’ ì„ë² ë”© â†’ ìœ ì‚¬ë„ ê²€ìƒ‰ â†’ ìš”ì•½ LLM |\n",
      "| **ì½”ë“œ ì–´ì‹œìŠ¤í„´íŠ¸** | ì‚¬ìš©ì ì½”ë“œ ìŠ¤ë‹ˆí« â†’ ì •ì  ë¶„ì„ â†’ LLMì—ê²Œ â€œë²„ê·¸ ì°¾ê¸°â€ ìš”ì²­ |\n",
      "| **ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤** | ì¬ë¬´ ë³´ê³ ì„œ â†’ ë²¡í„° ê²€ìƒ‰ â†’ â€œ2023ë…„ ë§¤ì¶œ ì¶”ì„¸ëŠ”?â€ ì§ˆë¬¸ |\n",
      "| **ìë™í™” ì›Œí¬í”Œë¡œ** | â€œë‚´ì¼ íšŒì˜ ì¼ì • ì¡ì•„ì¤˜â€ â†’ ìº˜ë¦°ë” API í˜¸ì¶œ â†’ í™•ì¸ ë©”ì¼ ì „ì†¡ |\n",
      "| **êµìœ¡Â·í•™ìŠµ** | êµì¬ ë‚´ìš© â†’ í€´ì¦ˆ ìƒì„± â†’ í•™ìŠµì ì‘ë‹µ â†’ ë§ì¶¤í˜• í”¼ë“œë°± ì œê³µ |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. ê°„ë‹¨í•œ ì—”ë“œâ€‘íˆ¬â€‘ì—”ë“œ ì˜ˆì‹œ (Python)\n",
      "\n",
      "ì•„ë˜ ì½”ë“œëŠ” **â€œë¬¸ì„œ ê²€ìƒ‰ + ì§ˆë¬¸â€‘ë‹µë³€â€** íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•œ ìµœì†Œ ì˜ˆì‹œì…ë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "# 1ï¸âƒ£ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
      "# pip install langchain openai faiss-cpu tiktoken\n",
      "\n",
      "from langchain.llms import OpenAI\n",
      "from langchain.embeddings import OpenAIEmbeddings\n",
      "from langchain.vectorstores import FAISS\n",
      "from langchain.prompts import PromptTemplate\n",
      "from langchain.chains import RetrievalQAChain\n",
      "\n",
      "# 2ï¸âƒ£ LLMÂ·ì„ë² ë”© ì´ˆê¸°í™”\n",
      "llm = OpenAI(model=\"gpt-4o-mini\")\n",
      "emb = OpenAIEmbeddings()\n",
      "\n",
      "# 3ï¸âƒ£ ë¬¸ì„œ ë¡œë“œ & ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
      "texts = [\n",
      "    \"ì„œìš¸ì€ ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ì´ë©°, í•œê°•ì„ ë¼ê³  ìˆë‹¤.\",\n",
      "    \"ë¶€ì‚°ì€ ë‚¨í•´ì•ˆì— ìœ„ì¹˜í•œ í•­êµ¬ ë„ì‹œì´ë‹¤.\",\n",
      "    \"ì œì£¼ë„ëŠ” í™”ì‚°ì„¬ì´ë©°, ê´€ê´‘ ëª…ì†Œê°€ ë§ë‹¤.\"\n",
      "]\n",
      "vectorstore = FAISS.from_texts(texts, emb)\n",
      "\n",
      "# 4ï¸âƒ£ Retriever ì •ì˜\n",
      "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
      "\n",
      "# 5ï¸âƒ£ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLMì— ì „ë‹¬)\n",
      "qa_prompt = PromptTemplate.from_template(\n",
      "    \"\"\"ì•„ë˜ëŠ” ì‚¬ìš©ìê°€ ì§ˆë¬¸í•œ ë‚´ìš©ê³¼ ê´€ë ¨ëœ ë¬¸ì„œ ì¡°ê°ë“¤ì´ë‹¤.\n",
      "ë¬¸ì„œ:\\n{context}\\n\\nì§ˆë¬¸: {question}\\në‹µë³€ì„ í•œêµ­ì–´ë¡œ, ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ë¼.\"\"\"\n",
      ")\n",
      "\n",
      "# 6ï¸âƒ£ RetrievalQAChain êµ¬ì„±\n",
      "qa_chain = RetrievalQAChain.from_chain_type(\n",
      "    llm=llm,\n",
      "    chain_type=\"stuff\",               # â€œstuffâ€ëŠ” ëª¨ë“  ë¬¸ì„œë¥¼ í•œ ë²ˆì— LLMì— ì „ë‹¬\n",
      "    retriever=retriever,\n",
      "    return_source_documents=True,\n",
      "    combine_prompt=qa_prompt,\n",
      ")\n",
      "\n",
      "# 7ï¸âƒ£ ì§ˆë¬¸ ì‹¤í–‰\n",
      "query = \"í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€?\"\n",
      "result = qa_chain({\"query\": query})\n",
      "\n",
      "print(\"ë‹µë³€:\", result[\"answer\"])\n",
      "print(\"\\nì‚¬ìš©ëœ ë¬¸ì„œ:\", [doc.page_content for doc in result[\"source_documents\"]])\n",
      "```\n",
      "\n",
      "**ë™ì‘ íë¦„**  \n",
      "1. í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© â†’ FAISSì— ì €ì¥  \n",
      "2. ì‚¬ìš©ìê°€ ì§ˆë¬¸ â†’ Retrieverê°€ ê°€ì¥ ìœ ì‚¬í•œ 2ê°œì˜ ë¬¸ì„œ ë°˜í™˜  \n",
      "3. í”„ë¡¬í”„íŠ¸ì— `context`(ê²€ìƒ‰ ê²°ê³¼)ì™€ `question`ì„ ì‚½ì… â†’ LLMì´ ìµœì¢… ë‹µë³€ ìƒì„±  \n",
      "\n",
      "---\n",
      "\n",
      "## 5. ì‹œì‘í•˜ê¸° ìœ„í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
      "\n",
      "| ë‹¨ê³„ | ë‚´ìš© | ì°¸ê³  ìë£Œ |\n",
      "|------|------|-----------|\n",
      "| **1. í™˜ê²½ ì„¤ì •** | Pythonâ€¯3.9+, `pip install langchain openai` | ê³µì‹ ì„¤ì¹˜ ê°€ì´ë“œ |\n",
      "| **2. API í‚¤** | OpenAI, Anthropic ë“± ì‚¬ìš©í•˜ê³ ì í•˜ëŠ” LLM ì œê³µìì˜ API í‚¤ ì„¤ì • (`export OPENAI_API_KEY=â€¦`) | ê° ì œê³µì ë¬¸ì„œ |\n",
      "| **3. ê¸°ë³¸ íŠœí† ë¦¬ì–¼** | â€œHello LangChainâ€ ì˜ˆì œ (LLMChain, PromptTemplate) | <https://python.langchain.com/docs/get_started/introduction> |\n",
      "| **4. Retrieval** | ë²¡í„° ìŠ¤í† ì–´ì™€ Retriever ì—°ê²° | <https://python.langchain.com/docs/modules/data_connection/vectorstores/> |\n",
      "| **5. Agent** | ë„êµ¬ì™€ ì—ì´ì „íŠ¸ êµ¬í˜„ (ì˜ˆ: ì›¹ ê²€ìƒ‰, DB ì¿¼ë¦¬) | <https://python.langchain.com/docs/modules/agents/> |\n",
      "| **6. ë°°í¬** | `LangServe` ë¡œ REST API ë§Œë“¤ê¸° ë˜ëŠ” `Docker` ì´ë¯¸ì§€í™” | <https://github.com/langchain-ai/langserve> |\n",
      "| **7. ì»¤ë®¤ë‹ˆí‹°** | LangChain Hub(í”„ë¡¬í”„íŠ¸Â·ì²´ì¸ ê³µìœ ), Discord, GitHub Discussions | `hub.langchain.com` |\n",
      "\n",
      "---\n",
      "\n",
      "## 6. í•œ ì¤„ ìš”ì•½\n",
      "\n",
      "> **LangChainì€ LLMì„ â€œí”„ë¡¬í”„íŠ¸ â†’ ê²€ìƒ‰/ë„êµ¬ â†’ ë©”ëª¨ë¦¬ â†’ ì¶œë ¥â€ì´ë¼ëŠ” **ëª¨ë“ˆí˜• íŒŒì´í”„ë¼ì¸**ìœ¼ë¡œ ì‰½ê²Œ ì¡°ë¦½Â·ìš´ì˜**í•  ìˆ˜ ìˆê²Œ í•´ ì£¼ëŠ” í”„ë ˆì„ì›Œí¬ì´ë©°, ë³µì¡í•œ AIâ€‘ì•±ì„ ë¹ ë¥´ê²Œ í”„ë¡œí† íƒ€ì´í•‘í•˜ê³  í”„ë¡œë•ì…˜ì— ë°°í¬í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "print(type(response))\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
