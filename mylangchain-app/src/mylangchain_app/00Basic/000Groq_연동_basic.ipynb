{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c628d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello LangChain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3b91443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_E\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "#load_dotenv(dotenv_path='.env')\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa569f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt + llm + output \n",
    "\n",
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a792f11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "System: 당신은 개발자입니다.\n",
      "Human: 파이썬은 무엇인가요? 자세하게 설명해주세요\n"
     ]
    }
   ],
   "source": [
    "prompt_text = prompt.format(input=\"파이썬은 무엇인가요? 자세하게 설명해주세요\")\n",
    "print(type(prompt_text))\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7211c146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n",
      "client=<openai.resources.chat.completions.completions.Completions object at 0x00000216AC1EB6B0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000216AC1EB9B0> root_client=<openai.OpenAI object at 0x00000216AC1EB530> root_async_client=<openai.AsyncOpenAI object at 0x00000216AC1FE0C0> model_name='openai/gpt-oss-120b' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "#llm = ChatOpenAI(api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(type(llm))\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac0db770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "응답: ## 파이썬(Python)이란?\n",
      "\n",
      "파이썬은 **고수준(high‑level), 인터프리터 방식, 동적 타이핑(dynamic typing)** 을 지원하는 프로그래밍 언어입니다. 1991년 네덜란드의 프로그래머 **귀도 반 로썸(Guido van Rossum)** 이 처음 발표했으며, 현재는 전 세계 수많은 개발자와 기업이 널리 사용하고 있습니다.  \n",
      "\n",
      "---\n",
      "\n",
      "## 1. 파이썬의 주요 특징\n",
      "\n",
      "| 특징 | 설명 | 장점 |\n",
      "|------|------|------|\n",
      "| **읽기 쉬운 문법** | 들여쓰기(Indentation)로 블록을 구분하고, 불필요한 기호(세미콜론, 중괄호 등)가 거의 없음 | 코드 가독성·유지보수성이 뛰어남 |\n",
      "| **동적 타이핑** | 변수 선언 시 타입을 명시하지 않음 (`x = 10` → 정수, `x = \"hello\"` → 문자열) | 빠른 프로토타이핑·코드량 감소 |\n",
      "| **인터프리터 언어** | 소스 코드를 바로 실행(컴파일 단계가 없음) | 즉시 피드백·디버깅이 용이 |\n",
      "| **다중 패러다임** | 절차적, 객체지향(OOP), 함수형 프로그래밍 지원 | 다양한 문제 해결 방식 선택 가능 |\n",
      "| **풍부한 표준 라이브러리** | 파일 I/O, 네트워킹, 웹, 데이터베이스, 압축 등 2천 개 이상의 모듈 포함 | 외부 패키지 없이도 많은 작업 수행 가능 |\n",
      "| **광범위한 서드파티 생태계** | `pip`(패키지 매니저)를 통해 PyPI(Python Package Index)에서 300,000+ 패키지 설치 가능 | 과학·데이터, 웹, 머신러닝, 자동화 등 거의 모든 분야에 적용 |\n",
      "| **플랫폼 독립성** | Windows, macOS, Linux, BSD, 심지어 모바일(iOS/Android)까지 지원 | 한 번 작성하면 다양한 환경에서 실행 가능 |\n",
      "| **대규모 커뮤니티** | 공식 문서, 튜토리얼, Stack Overflow, GitHub, 국내·외 모임 등 | 문제 해결·학습 자료가 풍부 |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. 파이썬의 역사와 버전\n",
      "\n",
      "| 연도 | 주요 사건 |\n",
      "|------|-----------|\n",
      "| **1989** | 귀도 반 로썸이 “아름답고 쉬운 언어”를 만들겠다는 목표로 프로젝트 시작 |\n",
      "| **1991** | 파이썬 0.9.0 공개 (예외 처리, 함수, 모듈) |\n",
      "| **2000** | 파이썬 2.0 출시 – 리스트 컴프리헨션, 가비지 컬렉션 등 |\n",
      "| **2008** | 파이썬 3.0 출시 – 문자열(Unicode) 기본화, `print` 함수, `range` 등 비호환적 변화 |\n",
      "| **2020** | 파이썬 2.7 공식 지원 종료 (EOL) |\n",
      "| **2023** | 최신 장기 지원(LTS) 버전은 3.11 (성능 개선) |\n",
      "| **2025** | 현재 최신 안정 버전은 **Python 3.13** (예정) |\n",
      "\n",
      "> **주의**: 파이썬 2와 파이썬 3는 문법·표준 라이브러리에서 호환성이 크게 다르므로, 새 프로젝트는 반드시 3.x 버전을 사용하세요.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. 파이썬이 쓰이는 분야\n",
      "\n",
      "| 분야 | 활용 예시 | 주요 라이브러리/프레임워크 |\n",
      "|------|----------|----------------------------|\n",
      "| **웹 개발** | 백엔드 API, 서버 사이드 로직 | Django, Flask, FastAPI, Tornado |\n",
      "| **데이터 과학·분석** | 통계 분석, 시각화, 데이터 전처리 | NumPy, pandas, Matplotlib, Seaborn |\n",
      "| **머신러닝·AI** | 모델 학습·배포, 딥러닝 | Scikit‑learn, TensorFlow, PyTorch, Keras |\n",
      "| **자동화·스크립트** | 파일·시스템 관리, 테스트 자동화 | `os`, `subprocess`, `shutil`, `pyautogui` |\n",
      "| **과학·공학** | 시뮬레이션, 수치 해석 | SciPy, SymPy, Jupyter Notebook |\n",
      "| **게임 개발** | 간단 2D/3D 게임, 프로토타입 | Pygame, Panda3D |\n",
      "| **네트워크·보안** | 패킷 분석, 취약점 스캐너 | Scapy, Paramiko, Requests |\n",
      "| **데스크톱 앱** | GUI 애플리케이션 | Tkinter, PyQt, Kivy |\n",
      "| **임베디드·IoT** | 라즈베리파이, 마이크로컨트롤러 | MicroPython, CircuitPython |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. 파이썬 기본 문법 소개\n",
      "\n",
      "아래 예제는 파이썬의 핵심 문법을 간단히 보여줍니다.\n",
      "\n",
      "```python\n",
      "# 1️⃣ 변수와 동적 타이핑\n",
      "x = 10          # 정수\n",
      "x = \"hello\"     # 문자열로 재할당 가능\n",
      "\n",
      "# 2️⃣ 리스트와 리스트 컴프리헨션\n",
      "nums = [1, 2, 3, 4, 5]\n",
      "squared = [n**2 for n in nums]   # [1, 4, 9, 16, 25]\n",
      "\n",
      "# 3️⃣ 함수 정의와 기본 인자\n",
      "def greet(name=\"World\"):\n",
      "    return f\"Hello, {name}!\"\n",
      "\n",
      "print(greet())          # Hello, World!\n",
      "print(greet(\"Python\"))  # Hello, Python!\n",
      "\n",
      "# 4️⃣ 조건문과 반복문\n",
      "for n in nums:\n",
      "    if n % 2 == 0:\n",
      "        print(f\"{n}은 짝수\")\n",
      "    else:\n",
      "        print(f\"{n}은 홀수\")\n",
      "\n",
      "# 5️⃣ 클래스와 객체지향\n",
      "class Animal:\n",
      "    def __init__(self, name):\n",
      "        self.name = name\n",
      "\n",
      "    def speak(self):\n",
      "        raise NotImplementedError\n",
      "\n",
      "class Dog(Animal):\n",
      "    def speak(self):\n",
      "        return \"멍멍!\"\n",
      "\n",
      "my_dog = Dog(\"바둑이\")\n",
      "print(my_dog.name)   # 바둑이\n",
      "print(my_dog.speak())# 멍멍!\n",
      "```\n",
      "\n",
      "### 주요 문법 포인트\n",
      "\n",
      "| 구분 | 특징 | 예시 |\n",
      "|------|------|------|\n",
      "| **들여쓰기** | 블록 구분에 탭(4 spaces 권장) 사용 | `if`, `for`, `def` 등 |\n",
      "| **주석** | `#` 한 줄 주석, `\"\"\"` 혹은 `'''` 로 다중 라인 주석(문서화 문자열) | `# 이것은 주석` |\n",
      "| **데이터 타입** | `int`, `float`, `bool`, `str`, `list`, `tuple`, `set`, `dict` 등 | `my_dict = {\"a\": 1, \"b\": 2}` |\n",
      "| **예외 처리** | `try/except/finally` 구문 | `try: ... except ValueError as e: ...` |\n",
      "| **모듈·패키지** | `import` 로 외부 코드 사용 | `import math; math.sqrt(9)` |\n",
      "| **리스트·딕셔너리 컴프리헨션** | 한 줄로 컬렉션 변환·생성 | `{k: v**2 for k, v in my_dict.items()}` |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. 파이썬 실행 환경\n",
      "\n",
      "| 환경 | 설명 | 설치 방법 |\n",
      "|------|------|-----------|\n",
      "| **CPython** | 공식 구현 (C로 작성) – 가장 널리 사용 | `python.org`에서 다운로드 |\n",
      "| **Anaconda** | 과학·데이터 분석용 배포판 (패키지·가상환경 관리) | `conda install anaconda` |\n",
      "| **PyPy** | JIT(Just‑In‑Time) 컴파일러 기반, 빠른 실행 속도 | `pypy.org` |\n",
      "| **MicroPython** | 마이크로컨트롤러용 경량 파이썬 | `micropython.org` |\n",
      "| **Jupyter Notebook / Lab** | 웹 기반 인터랙티브 환경 | `pip install notebook` |\n",
      "| **IDE/Editor** | VS Code, PyCharm, Sublime Text, vim, Emacs 등 | 각 IDE 공식 사이트 참고 |\n",
      "\n",
      "> **가상 환경(Virtual Environment)**  \n",
      "> 프로젝트마다 독립된 패키지 집합을 관리하려면 `venv`(표준) 혹은 `conda`를 사용합니다. 예시:\n",
      "> ```bash\n",
      "> python -m venv myenv      # 가상 환경 생성\n",
      "> source myenv/bin/activate # (Linux/macOS) 활성화\n",
      "> myenv\\Scripts\\activate    # (Windows) 활성화\n",
      "> ```\n",
      "\n",
      "---\n",
      "\n",
      "## 6. 파이썬 학습 로드맵 (입문 → 중급 → 고급)\n",
      "\n",
      "1. **입문**  \n",
      "   - 기본 문법, 변수·제어문·함수·자료구조  \n",
      "   - `print`, `input`, `len`, `type` 등 내장 함수 활용  \n",
      "   - 작은 프로젝트: 계산기, 파일 복사 스크립트, 텍스트 분석 등  \n",
      "\n",
      "2. **중급**  \n",
      "   - 객체지향 프로그래밍(OOP) : 클래스·상속·다형성  \n",
      "   - 모듈·패키지 구조 설계, `__init__.py` 활용  \n",
      "   - 예외 처리, 로깅(`logging`), 파일 입출력(`with open`)  \n",
      "   - 외부 라이브러리 사용 (`pip install requests`, `beautifulsoup4` 등)  \n",
      "\n",
      "3. **고급**  \n",
      "   - 고성능 최적화: `Cython`, `Numba`, `multiprocessing`  \n",
      "   - 비동기 프로그래밍: `asyncio`, `await`  \n",
      "   - 테스트·CI: `unittest`, `pytest`, GitHub Actions  \n",
      "   - 배포: `setuptools`, `wheel`, `twine`, Docker 컨테이너  \n",
      "   - 디자인 패턴, 메타프로그래밍, 타입 힌트(`typing`)  \n",
      "\n",
      "4. **전문화** (분야별)  \n",
      "   - **웹** → Django/Flask/ FastAPI, ORM, REST API 설계  \n",
      "   - **데이터** → pandas, NumPy, 시각화, Jupyter, SQLAlchemy  \n",
      "   - **AI** → TensorFlow/PyTorch, 데이터 파이프라인, 모델 서빙  \n",
      "   - **자동화** → Selenium, PyAutoGUI, CI/CD 스크립트  \n",
      "\n",
      "---\n",
      "\n",
      "## 7. 파이썬을 선택해야 하는 이유\n",
      "\n",
      "| 상황 | 파이썬이 강점이 되는 이유 |\n",
      "|------|--------------------------|\n",
      "| **빠른 프로토타이핑** | 짧은 코드와 풍부한 라이브러리로 아이디어를 즉시 구현 |\n",
      "| **다양한 분야 진입** | 웹·데스크톱·데이터·AI·임베디드까지 하나의 언어로 커버 |\n",
      "| **교육·학습** | 문법이 직관적이라 프로그래밍 입문에 최적 |\n",
      "| **커뮤니티 지원** | Stack Overflow, GitHub, 국내·외 스터디가 활발 |\n",
      "| **기업 채용** | 구글, 넷플릭스, 인스타그램 등 대기업·스타트업 모두 사용 |\n",
      "\n",
      "---\n",
      "\n",
      "## 8. 자주 묻는 질문(FAQ)\n",
      "\n",
      "| 질문 | 답변 |\n",
      "|------|------|\n",
      "| **파이썬은 컴파일 언어인가요?** | 아니요. 파이썬은 인터프리터 언어이며, 실행 시 바이트코드(`.pyc`)로 변환됩니다. 하지만 `PyPy` 같은 JIT 구현은 실행 속도를 크게 향상시킵니다. |\n",
      "| **파이썬 2와 3 중 어느 버전을 써야 하나요?** | 2.x는 2020년 1월에 공식 지원이 종료되었습니다. 새로운 프로젝트는 반드시 3.x(현재는 3.11 이상) 버전을 사용하세요. |\n",
      "| **속도가 느리다고 들었는데, 어떻게 개선할 수 있나요?** | *프로파일링*(`cProfile`)으로 병목을 찾고, `NumPy` 같은 C 기반 라이브러리 활용, `Cython`/`Numba`로 핵심 로직을 컴파일, `asyncio`·멀티프로세싱으로 I/O·CPU 병렬화 등을 적용합니다. |\n",
      "| **가상 환경 없이 전역에 패키지를 설치하면 안 되나요?** | 가능하지만, 프로젝트마다 의존성이 다를 수 있어 충돌 위험이 큽니다. 가상 환경을 사용하면 서로 다른 프로젝트가 서로 다른 패키지 버전을 독립적으로 유지할 수 있습니다. |\n",
      "| **파이썬으로 모바일 앱을 만들 수 있나요?** | 직접적인 네이티브 앱 개발은 제한적이지만, `Kivy`, `BeeWare`, `PySide` 등을 이용해 크로스플랫폼 앱을 만들 수 있습니다. 또한 백엔드 API를 파이썬으로 구현하고, 프론트엔드는 다른 언어(예: Flutter)와 연동하는 방법이 일반적입니다. |\n",
      "\n",
      "---\n",
      "\n",
      "## 9. 시작하기 위한 실전 팁\n",
      "\n",
      "1. **공식 튜토리얼** – <https://docs.python.org/3/tutorial/> (영문) 혹은 <https://wikidocs.net/1> (한국어)  \n",
      "2. **핸즈‑온 프로젝트** – “Todo List 웹앱”, “CSV → Excel 변환기”, “간단한 챗봇” 등 작은 목표를 정하고 바로 구현해 보기.  \n",
      "3. **코드 리뷰** – GitHub에 코드를 올리고 다른 사람에게 피드백 받기.  \n",
      "4. **문제 풀이** – 백준, 프로그래머스, LeetCode 등에서 파이썬으로 알고리즘 문제 풀기.  \n",
      "5. **패키지 관리** – `pip list`, `pip freeze > requirements.txt`, `pip install -r requirements.txt` 로 의존성 관리 습관화.  \n",
      "\n",
      "---\n",
      "\n",
      "## 10. 마무리\n",
      "\n",
      "파이썬은 **“읽기 쉽고, 쓰기 쉬우며, 배우기 쉬운”** 언어라는 슬로건을 충실히 구현한 도구입니다. 초보자부터 전문가까지, 다양한 도메인에서 생산성을 크게 높여 주는 만큼 **지속적인 학습과 실전 적용**을 통해 실력을 키워 나가길 권합니다.  \n",
      "\n",
      "궁금한 점이 있으면 언제든 물어보세요! 🚀\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8d8769",
   "metadata": {},
   "source": [
    "LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c3d495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb326fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000216AC1EB6B0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000216AC1EB9B0>, root_client=<openai.OpenAI object at 0x00000216AC1EB530>, root_async_client=<openai.AsyncOpenAI object at 0x00000216AC1FE0C0>, model_name='openai/gpt-oss-120b', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6dc5edfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input\":\"LangChain은 무엇인가요?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3058038c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "**LangChain**은 **대규모 언어 모델(LLM)** 을 활용한 **애플리케이션**을 보다 쉽고 효율적으로 개발할 수 있게 도와주는 **오픈소스 프레임워크**입니다.  \n",
      "주요 목표는 “LLM을 단순히 질문‑답변 엔진으로 쓰는 수준을 넘어, **데이터 연동·프롬프트 관리·워크플로우 제어**까지 포함한 **복합적인 애플리케이션**을 만들 수 있게 하는 것”입니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ 핵심 개념\n",
      "\n",
      "| 요소 | 설명 | 주요 역할 |\n",
      "|------|------|-----------|\n",
      "| **Chains** | 여러 **Component**(LLM, Prompt, Tool 등)를 순차·조건부로 연결한 흐름 | 프롬프트 생성 → LLM 호출 → 결과 후처리 등 복잡한 로직을 한 번에 정의 |\n",
      "| **Agents** | **동적**으로 **Tool**(검색 API, DB, 계산기 등)을 선택·호출하는 **자율적인** 엔티티 | “날씨를 알려줘” → 검색 → LLM에게 요약 요청 등 상황에 맞게 도구를 사용 |\n",
      "| **Prompts** | 템플릿 기반의 **프롬프트 관리**·**동적 변수 삽입** | 재사용 가능한 프롬프트, 체인별 파라미터 관리 |\n",
      "| **Memory** | 대화·작업 흐름에서 **상태(컨텍스트)를 유지** | 챗봇에서 이전 대화를 기억하거나, 단계별 결과를 누적 |\n",
      "| **Indexes / Retrieval** | 문서·데이터베이스를 **벡터화·검색**하여 LLM에 **컨텍스트** 제공 | RAG(Retrieval‑Augmented Generation) 파이프라인 구현 |\n",
      "| **Tools** | 외부 서비스·함수·API 등 **LLM이 호출할 수 있는 기능** | 검색 엔진, 데이터베이스, 계산기, 웹 스크래핑 등 |\n",
      "| **Callbacks** | 실행 흐름에 **후킹**(로그, 메트릭, 트레이싱) | 디버깅·성능 모니터링·사용자 피드백 수집 |\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ 주요 구성 요소 (Python 예시)\n",
      "\n",
      "```python\n",
      "from langchain.llms import OpenAI\n",
      "from langchain.prompts import PromptTemplate\n",
      "from langchain.chains import LLMChain\n",
      "from langchain.memory import ConversationBufferMemory\n",
      "\n",
      "# 1️⃣ Prompt 템플릿 정의\n",
      "prompt = PromptTemplate(\n",
      "    input_variables=[\"question\"],\n",
      "    template=\"You are a helpful assistant. Answer the question concisely:\\n{question}\"\n",
      ")\n",
      "\n",
      "# 2️⃣ LLM 인스턴스 (OpenAI, Anthropic, Cohere 등)\n",
      "llm = OpenAI(model=\"gpt-4\", temperature=0.2)\n",
      "\n",
      "# 3️⃣ 체인 생성 (Prompt → LLM)\n",
      "chain = LLMChain(prompt=prompt, llm=llm)\n",
      "\n",
      "# 4️⃣ 메모리(대화 기록) 연결 (선택 사항)\n",
      "memory = ConversationBufferMemory()\n",
      "chain.memory = memory\n",
      "\n",
      "# 사용\n",
      "response = chain.run({\"question\": \"한국의 수도는 어디인가?\"})\n",
      "print(response)   # → \"서울입니다.\"\n",
      "```\n",
      "\n",
      "위 예시는 **프롬프트 → LLM → 메모리** 라는 가장 기본적인 체인을 만든 것입니다. 실제 서비스에서는 `Retriever`, `Agent`, `Tool` 등을 조합해 복합적인 흐름을 구현합니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ 왜 LangChain을 사용하나요?\n",
      "\n",
      "| 필요 상황 | LangChain이 제공하는 해결책 |\n",
      "|----------|----------------------------|\n",
      "| **LLM과 외부 데이터 결합** | Retrieval‑Augmented Generation (RAG) 파이프라인을 손쉽게 구축 |\n",
      "| **다단계 작업** | 여러 LLM 호출·전처리·후처리를 하나의 `Chain`으로 선언 |\n",
      "| **도구 활용** | 검색, 계산, 파일 I/O 등 다양한 `Tool`을 자동으로 선택·호출하는 `Agent` |\n",
      "| **대화 상태 유지** | `Memory`를 통해 대화 흐름을 자연스럽게 이어감 |\n",
      "| **프롬프트 관리** | 템플릿, 변수, 버전 관리가 체계화돼 재사용·협업이 쉬움 |\n",
      "| **관찰 가능성** | `Callbacks`로 로그·메트릭·에러 추적이 가능해 디버깅·모니터링이 용이 |\n",
      "| **멀티‑LLM/멀티‑프레임워크** | OpenAI, Anthropic, Llama, Cohere, HuggingFace 등 다양한 모델을 동일 인터페이스로 교체 가능 |\n",
      "\n",
      "---\n",
      "\n",
      "## 4️⃣ 주요 사용 사례\n",
      "\n",
      "| 분야 | 구체적인 예시 |\n",
      "|------|---------------|\n",
      "| **고객지원 챗봇** | 과거 티켓 기록을 `VectorStore`에 저장 → 사용자가 질문하면 검색 → LLM이 답변 |\n",
      "| **문서 요약·검색** | 사내 위키를 임베딩 → 검색 후 LLM이 요약 제공 |\n",
      "| **데이터 분석 어시스턴트** | Pandas 코드 자동 생성·실행 → 결과 시각화까지 한 번에 |\n",
      "| **코드 생성·디버깅** | `Tool`로 IDE API 호출 → LLM이 코드 제안 → 실행 결과 피드백 |\n",
      "| **비즈니스 의사결정** | 여러 외부 API(주가, 날씨, 뉴스) 호출 → LLM이 종합 보고서 작성 |\n",
      "| **교육·튜터** | 학생의 이전 답변을 `Memory`에 저장 → 맞춤형 피드백 제공 |\n",
      "\n",
      "---\n",
      "\n",
      "## 5️⃣ LangChain 생태계\n",
      "\n",
      "| 영역 | 프로젝트/패키지 |\n",
      "|------|-----------------|\n",
      "| **Core** | `langchain` (Python) – 기본 프레임워크 |\n",
      "| **JavaScript/TypeScript** | `langchainjs` – Node.js 환경용 |\n",
      "| **LangChain Hub** | 프리‑빌드 **Prompt**, **Chain**, **Agent** 템플릿 공유 마켓플레이스 |\n",
      "| **Integrations** | `langchain-community` – 다양한 Vector DB (FAISS, Pinecone, Weaviate 등), LLM 제공자, 검색 엔진 등 |\n",
      "| **LangSmith** | (유료) 실행 트레이싱·데이터 라벨링·프롬프트 테스트 플랫폼 |\n",
      "| **LangChain UI** | 시각화 대시보드 (체인 설계·디버깅) |\n",
      "\n",
      "---\n",
      "\n",
      "## 6️⃣ 시작하기 (간단 가이드)\n",
      "\n",
      "1. **환경 준비**  \n",
      "   ```bash\n",
      "   pip install langchain openai  # 기본 패키지\n",
      "   # 필요 시 vector DB, 검색 엔진 등 추가 설치\n",
      "   ```\n",
      "\n",
      "2. **API 키 설정**  \n",
      "   ```bash\n",
      "   export OPENAI_API_KEY=\"sk-...\"\n",
      "   ```\n",
      "\n",
      "3. **첫 번째 체인 만들기**  \n",
      "   위의 Python 예시를 그대로 실행해 보세요.\n",
      "\n",
      "4. **RAG 파이프라인 구축** (예시)\n",
      "\n",
      "   ```python\n",
      "   from langchain.vectorstores import FAISS\n",
      "   from langchain.embeddings import OpenAIEmbeddings\n",
      "   from langchain.chains import RetrievalQA\n",
      "\n",
      "   # 1) 문서 로드 & 임베딩\n",
      "   docs = [\"문서 1 내용...\", \"문서 2 내용...\"]\n",
      "   embeddings = OpenAIEmbeddings()\n",
      "   vectorstore = FAISS.from_texts(docs, embeddings)\n",
      "\n",
      "   # 2) Retriever\n",
      "   retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
      "\n",
      "   # 3) QA 체인\n",
      "   qa = RetrievalQA.from_chain_type(\n",
      "       llm=OpenAI(model=\"gpt-4\"),\n",
      "       chain_type=\"stuff\",\n",
      "       retriever=retriever,\n",
      "   )\n",
      "\n",
      "   # 질문\n",
      "   print(qa.run(\"한국의 전통 음식은 무엇인가?\"))\n",
      "   ```\n",
      "\n",
      "5. **Agent 활용** (검색 + 요약)\n",
      "\n",
      "   ```python\n",
      "   from langchain.agents import initialize_agent, Tool\n",
      "   from langchain.tools import DuckDuckGoSearchRun\n",
      "\n",
      "   search = DuckDuckGoSearchRun()\n",
      "   tools = [Tool(name=\"Search\", func=search.run, description=\"웹 검색\")]\n",
      "\n",
      "   agent = initialize_agent(\n",
      "       tools,\n",
      "       llm=OpenAI(model=\"gpt-4\"),\n",
      "       agent_type=\"zero-shot-react-description\",\n",
      "       verbose=True,\n",
      "   )\n",
      "\n",
      "   agent.run(\"최근 AI 트렌드에 대해 3줄 요약해줘\")\n",
      "   ```\n",
      "\n",
      "---\n",
      "\n",
      "## 7️⃣ 한계와 주의점\n",
      "\n",
      "| 이슈 | 설명 | 대응 방안 |\n",
      "|------|------|-----------|\n",
      "| **비용** | LLM 호출·벡터 검색 모두 비용이 발생 | 토큰 최적화, 캐시, 저렴한 모델 사용 |\n",
      "| **보안·프라이버시** | 외부 API 호출 시 데이터 유출 위험 | 온프레미스 LLM·벡터 DB, 데이터 암호화 |\n",
      "| **프롬프트 엔지니어링** | 좋은 결과는 프롬프트 설계에 크게 의존 | PromptTemplate, Few‑Shot 예시, 테스트 자동화 |\n",
      "| **오류 처리** | LLM이 비논리적 답변을 줄 수 있음 | `OutputParser`, `Validator`, `Retry` 로직 추가 |\n",
      "| **버전 호환** | LangChain은 빠르게 업데이트됨 | `requirements.txt`에 고정 버전 명시, changelog 주시 |\n",
      "\n",
      "---\n",
      "\n",
      "## 8️⃣ 요약\n",
      "\n",
      "- **LangChain**은 LLM을 **프롬프트, 메모리, 검색, 도구**와 결합해 **복합적인 워크플로우**를 선언형으로 만들 수 있게 해주는 프레임워크입니다.  \n",
      "- **Chains**, **Agents**, **Memory**, **Retriever**, **Tool** 등 핵심 컴포넌트를 조합해 **챗봇, RAG, 데이터 분석, 자동화** 등 다양한 애플리케이션을 빠르게 구현합니다.  \n",
      "- Python, JavaScript 등 여러 언어를 지원하고, **LangChain Hub**와 **LangSmith** 같은 생태계 도구가 있어 협업·배포가 용이합니다.  \n",
      "- 올바른 프롬프트 설계와 비용·보안 관리만 하면, LLM 기반 서비스 개발 속도를 크게 끌어올릴 수 있습니다.\n",
      "\n",
      "궁금한 점이 있거나 구체적인 구현 예시가 필요하면 언제든 알려 주세요! 🚀\n"
     ]
    }
   ],
   "source": [
    "print(type(response))\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
