{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
   "metadata": {
    "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
   },
   "source": [
    "### LLM Chain 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9",
   "metadata": {
    "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9"
   },
   "source": [
    "## 1. 환경 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
   "metadata": {
    "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
   },
   "source": [
    "### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
    "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
   },
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "### 2) OpenAI 인증키 설정\n",
    "https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_Z\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e09aaca6-5aa2-4b52-bbfc-196e808dc5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.27\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
   "metadata": {
    "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
   },
   "source": [
    "## 2. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23729d10-9600-415b-b7d1-f954665224e3",
   "metadata": {
    "id": "23729d10-9600-415b-b7d1-f954665224e3"
   },
   "source": [
    "### 1) Prompt + LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "on0y4xF8VoyE",
   "metadata": {
    "id": "on0y4xF8VoyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"인공지능 모델의 학습 원리에 대하여 쉽게 설명해 주세요.\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dc4accf-c927-40a3-ba2c-f891c94c34f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='인공지능 모델의 학습 원리는 크게 다음과 같습니다.\\n\\n1.  **데이터 수집**: 인공지능 모델이 학습할 수 있도록 데이터를 수집합니다. 이 데이터는 모델이 학습할 수 있는 형태로 가공되어야 합니다.\\n2.  **데이터 전처리**: 수집된 데이터를 모델이 학습할 수 있도록 전처리합니다. 예를 들어, 이미지 데이터를 수집한 경우, 이미지를 픽셀 단위로 분해하여 숫자로 변환하는 과정이 필요합니다.\\n3.  **모델 정의**: 인공지능 모델을 정의합니다. 모델은 입력 데이터를 받아서 출력 데이터를 생성하는 함수로 정의할 수 있습니다. 예를 들어, 이미지 분류 모델은 입력 이미지로부터 카테고리를 분류하는 함수를 정의할 수 있습니다.\\n4.  **손실 함수 정의**: 모델의 성능을 평가하는 손실 함수를 정의합니다. 손실 함수는 모델의 출력과 실제 출력의 차이를 측정하는 함수로 정의할 수 있습니다. 예를 들어, 이미지 분류 모델의 경우, 크로스 엔트로피 손실 함수를 사용할 수 있습니다.\\n5.  **최적화**: 모델의 가중치를 업데이트하여 손실 함수를 최소화하는 최적화 알고리즘을 사용합니다. 예를 들어, 경사 하강법, Adam, RMSprop 등이 있습니다.\\n6.  **반복 학습**: 모델을 반복적으로 학습시켜 손실 함수를 최소화합니다. 이 과정은 모델이 수렴할 때까지 반복됩니다.\\n\\n예를 들어, 고양이와 강아지의 이미지를 분류하는 모델을 학습시킨다고 가정해 봅시다.\\n\\n*   **데이터 수집**: 고양이와 강아지의 이미지 데이터를 수집합니다.\\n*   **데이터 전처리**: 이미지를 픽셀 단위로 분해하여 숫자로 변환합니다.\\n*   **모델 정의**: 이미지 분류 모델을 정의합니다. 예를 들어, 컨볼루션 신경망(CNN)을 사용할 수 있습니다.\\n*   **손실 함수 정의**: 크로스 엔트로피 손실 함수를 정의합니다.\\n*   **최적화**: Adam 최적화 알고리즘을 사용합니다.\\n*   **반복 학습**: 모델을 반복적으로 학습시켜 손실 함수를 최소화합니다.\\n\\n이 과정을 통해 모델은 고양이와 강아지의 이미지를 분류하는 능력을 학습하게 됩니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 439, 'prompt_tokens': 24, 'total_tokens': 463, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.049678864, 'prompt_time': 0.000267816, 'completion_time': 1.020395789, 'total_time': 1.020663605}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_79da0e0073', 'id': 'chatcmpl-d0c4a35c-e9f7-4dd3-a3e2-8100970056c0', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--db6ac4cc-5c21-4795-a9a2-e99b804d5826-0' usage_metadata={'input_tokens': 24, 'output_tokens': 439, 'total_tokens': 463, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "WzcZy4PruV1n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "WzcZy4PruV1n",
    "outputId": "18ecc8f9-5748-4b16-cb07-4a0f7a01fb5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 크게 다음과 같습니다.\n",
      "\n",
      "1.  **데이터 수집**: 인공지능 모델이 학습할 수 있도록 데이터를 수집합니다. 이 데이터는 모델이 학습할 수 있는 형태로 가공되어야 합니다.\n",
      "2.  **데이터 전처리**: 수집된 데이터를 모델이 학습할 수 있도록 전처리합니다. 예를 들어, 이미지 데이터를 수집한 경우, 이미지를 픽셀 단위로 분해하여 숫자로 변환하는 과정이 필요합니다.\n",
      "3.  **모델 정의**: 인공지능 모델을 정의합니다. 모델은 입력 데이터를 받아서 출력 데이터를 생성하는 함수로 정의할 수 있습니다. 예를 들어, 이미지 분류 모델은 입력 이미지로부터 카테고리를 분류하는 함수를 정의할 수 있습니다.\n",
      "4.  **손실 함수 정의**: 모델의 성능을 평가하는 손실 함수를 정의합니다. 손실 함수는 모델의 출력과 실제 출력의 차이를 측정하는 함수로 정의할 수 있습니다. 예를 들어, 이미지 분류 모델의 경우, 크로스 엔트로피 손실 함수를 사용할 수 있습니다.\n",
      "5.  **최적화**: 모델의 가중치를 업데이트하여 손실 함수를 최소화하는 최적화 알고리즘을 사용합니다. 예를 들어, 경사 하강법, Adam, RMSprop 등이 있습니다.\n",
      "6.  **반복 학습**: 모델을 반복적으로 학습시켜 손실 함수를 최소화합니다. 이 과정은 모델이 수렴할 때까지 반복됩니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 이미지를 분류하는 모델을 학습시킨다고 가정해 봅시다.\n",
      "\n",
      "*   **데이터 수집**: 고양이와 강아지의 이미지 데이터를 수집합니다.\n",
      "*   **데이터 전처리**: 이미지를 픽셀 단위로 분해하여 숫자로 변환합니다.\n",
      "*   **모델 정의**: 이미지 분류 모델을 정의합니다. 예를 들어, 컨볼루션 신경망(CNN)을 사용할 수 있습니다.\n",
      "*   **손실 함수 정의**: 크로스 엔트로피 손실 함수를 정의합니다.\n",
      "*   **최적화**: Adam 최적화 알고리즘을 사용합니다.\n",
      "*   **반복 학습**: 모델을 반복적으로 학습시켜 손실 함수를 최소화합니다.\n",
      "\n",
      "이 과정을 통해 모델은 고양이와 강아지의 이미지를 분류하는 능력을 학습하게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c97fc",
   "metadata": {},
   "source": [
    "### 2) PromptTemplate + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "SeNi_VXqYD-b",
   "metadata": {
    "id": "SeNi_VXqYD-b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} template='You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01WLucSpYjZt",
   "metadata": {
    "id": "01WLucSpYjZt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 스스로 학습할 수 있도록 하는 것이죠.\\n\\n예를 들어, 고양이와 강아지의 사진을 구분하는 모델을 만든다고 가정해 봅시다.\\n\\n1. **데이터 수집**: 많은 고양이와 강아지의 사진을 수집합니다. 이 사진들이 바로 학습 데이터입니다.\\n2. **데이터 전처리**: 수집한 사진들을 컴퓨터가 처리할 수 있는 형태로 변환합니다. (예: 이미지 resizing, 픽셀값 조정 등)\\n3. **모델 설정**: 고양이와 강아지의 특징을 추출하고 구분할 수 있는 알고리즘을 선택합니다. (예: 신경망, 결정 트리 등)\\n4. **학습**: 모델에 학습 데이터를 입력하고, 모델이 스스로 고양이와 강아지의 특징을 학습하도록 합니다. 이 과정에서 모델은 사진의 픽셀값과 고양이/강아지 여부 간의 관계를 찾으려고 합니다.\\n5. **오차 계산**: 모델의 예측 결과와 실제 고양이/강아지 여부를 비교하여 오차를 계산합니다.\\n6. **모델 업데이트**: 오차를 최소화하기 위해 모델의 파라미터를 조정합니다. 이 과정이 반복되면서 모델은 점점 더 정확한 예측을 하게 됩니다.\\n\\n반복적인 학습과 업데이트를 통해 모델은 고양이와 강아지의 특징을 스스로 학습하고, 새로운 사진을 입력했을 때 고양이인지 강아지인지 구분할 수 있게 됩니다.\\n\\n이러한 학습 원리는 다양한 인공지능 모델에 적용될 수 있으며, 이를 통해 컴퓨터는 데이터를 통해 스스로 학습하고, 예측하고, 결정할 수 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 326, 'prompt_tokens': 36, 'total_tokens': 362, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.054430541, 'prompt_time': 0.000540559, 'completion_time': 0.755361268, 'total_time': 0.755901827}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_5d3e4e58e1', 'id': 'chatcmpl-6e7825d7-7e7a-4acc-8e2e-3fe73655fa44', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--fed01ee5-b55f-4449-96ae-46e45b726b10-0' usage_metadata={'input_tokens': 36, 'output_tokens': 326, 'total_tokens': 362, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))\n",
    "\n",
    "# chain 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "170ec878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 스스로 학습할 수 있도록 하는 것이죠.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 구분하는 모델을 만든다고 가정해 봅시다.\n",
      "\n",
      "1. **데이터 수집**: 많은 고양이와 강아지의 사진을 수집합니다. 이 사진들이 바로 학습 데이터입니다.\n",
      "2. **데이터 전처리**: 수집한 사진들을 컴퓨터가 처리할 수 있는 형태로 변환합니다. (예: 이미지 resizing, 픽셀값 조정 등)\n",
      "3. **모델 설정**: 고양이와 강아지의 특징을 추출하고 구분할 수 있는 알고리즘을 선택합니다. (예: 신경망, 결정 트리 등)\n",
      "4. **학습**: 모델에 학습 데이터를 입력하고, 모델이 스스로 고양이와 강아지의 특징을 학습하도록 합니다. 이 과정에서 모델은 사진의 픽셀값과 고양이/강아지 여부 간의 관계를 찾으려고 합니다.\n",
      "5. **오차 계산**: 모델의 예측 결과와 실제 고양이/강아지 여부를 비교하여 오차를 계산합니다.\n",
      "6. **모델 업데이트**: 오차를 최소화하기 위해 모델의 파라미터를 조정합니다. 이 과정이 반복되면서 모델은 점점 더 정확한 예측을 하게 됩니다.\n",
      "\n",
      "반복적인 학습과 업데이트를 통해 모델은 고양이와 강아지의 특징을 스스로 학습하고, 새로운 사진을 입력했을 때 고양이인지 강아지인지 구분할 수 있게 됩니다.\n",
      "\n",
      "이러한 학습 원리는 다양한 인공지능 모델에 적용될 수 있으며, 이를 통해 컴퓨터는 데이터를 통해 스스로 학습하고, 예측하고, 결정할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56848a4c",
   "metadata": {},
   "source": [
    "### 3) PromptTemplate + LLM(invoke()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d1e9009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'str'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 배우고, 판단하고, 결정하는 능력을 키우는 과정이라고 생각하면 쉽습니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델이 학습하려면 많은 데이터가 필요합니다. 이 데이터는 과거에 발생했던 일들의 기록이라고 생각하면 됩니다. 예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다. 이 모델을 학습시키기 위해서는 수많은 고양이와 강아지의 사진 데이터가 필요합니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집된 데이터를 모델이 이해할 수 있도록 가공하는 과정입니다. 이 과정에서는 데이터의 오류를 수정하거나, 필요한 정보를 추가하는 등의 작업이 이루어집니다.\n",
      "\n",
      "3. **모델 훈련**: 준비된 데이터를 바탕으로 모델을 훈련시킵니다. 이 과정에서는 모델이 데이터를 분석하고, 패턴을 찾아냅니다. 예를 들어, 고양이 사진에는 귀가 있고, 강아지 사진에는 귀가 있다든지, 고양이는 몸이 더 날씬하다든지 하는 특징들을 스스로 찾아냅니다.\n",
      "\n",
      "4. **예측 및 오류 수정**: 모델이 학습 데이터를 통해 패턴을 학습하면, 새로운 데이터를 가지고 예측을 시작합니다. 이때 예측 결과와 실제 값이 다를 경우, 모델은 오류를 계산하고, 그 오류를 줄이기 위해 스스로를 수정합니다. 이 과정이 반복되면서 모델의 정확도가 높아집니다.\n",
      "\n",
      "5. **모델 평가**: 학습이 완료된 후, 모델의 성능을 평가합니다. 이는 모델이 새로운, 보지 못한 데이터에 대해 얼마나 정확하게 예측하는지 확인하는 과정입니다.\n",
      "\n",
      "6. **모델 배포**: 모델의 성능이 만족할 만한 수준이면, 실제 문제 해결을 위해 배포합니다. 이 모델은 새로운 데이터를 지속적으로 처리하면서, 추가적인 학습을 통해 계속해서 개선될 수 있습니다.\n",
      "\n",
      "이러한 학습 원리는 신경망을 기반으로 하는 딥러닝 모델에도 동일하게 적용됩니다. 다만, 딥러닝 모델은 사람의 뇌처럼 여러 층의 뉴런(또는 노드)을 사용하여 복잡한 패턴을 학습할 수 있는 구조로 되어 있다는 점이 다릅니다. 각 층에서 데이터의 특징을 추출하고, 이 특징들을 조합하여 최종적으로는 입력 데이터에 대한 결과를 출력합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. \\\n",
    "                                      Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 2. chain 생성 (LCEL)\n",
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "\n",
    "# 3. chain의 invoke 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d997b16",
   "metadata": {},
   "source": [
    "### 4) PromptTemplate + LLM(stream()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "684654e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 스스로 학습할 수 있도록 하는 것입니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 보겠습니다. 이 모델에게 고양이와 강아지의 사진 여러 장을 보여 주고, 이것이 고양이인지 강아지인지를 알려줍니다.\n",
      "\n",
      "모델은 처음에 고양이와 강아지의 특징을 모르기 때문에, 사진을 보고 맞추는 것이 어렵습니다. 하지만 계속해서 사진을 보고 정답을 알려주면, 모델은 고양이는 고양이답게, 강아지는 강아지답게 생긴 특징을 스스로 찾아내기 시작합니다.\n",
      "\n",
      "이를 통해 모델은 고양이의 특징(예: 귀가 뾰족하다, 눈이 크다 등)과 강아지의 특징(예: 귀가 쳐져 있다, 꼬리가 길다 등)을 학습하게 됩니다. 이렇게 학습한 특징을 바탕으로 새로운 사진을 보여주면, 모델은 이를 보고 고양이인지 강아지인지를 맞출 수 있습니다.\n",
      "\n",
      "이러한 학습 과정을 통해 인공지능 모델은 점점 더 정확해지고, 다양한 문제를 해결할 수 있게 됩니다."
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. \\\n",
    "                                      Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "lm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "# 스트리밍 출력\n",
    "#print(answer)\n",
    "\n",
    "for token in answer:\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0188674-915f-41af-ac46-56f9f54289b0",
   "metadata": {
    "id": "b0188674-915f-41af-ac46-56f9f54289b0"
   },
   "source": [
    "##### 2) Multiple Chains\n",
    "* Multi Chain을 활용한 영화 추천 및 줄거리 요약 ( 잘 동작하지 않는 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
    "outputId": "7ee83878-5d1a-45e3-f033-100da33f3ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      " ===> 추천된 영화:\n",
      "**《밀어》(2012, *The Intouchables*)**를 추천드립니다.  \n",
      "프랑스 영화지만 드라마적 감정선이 강렬하고 인간적인 따뜻함이 뛰어나요.  \n",
      "실화를 바탕으로 한 이 작품은 신분, 신체적 한계, 우정에 대한 이야기를 유쾌하면서도 깊이 있게 풀어냅니다.  \n",
      "코미디와 감동이 절묘하게 어우러진 대표적인 드라마입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "movie = chain1.invoke({\"genre\": \"Drama\"})  # 영화 제목 얻기\n",
    "\n",
    "print(type(movie))\n",
    "print(\" ===> 추천된 영화:\")  # movie 값 출력\n",
    "print(movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16718b76-f59d-48f7-906f-5d2371417803",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "16718b76-f59d-48f7-906f-5d2371417803",
    "outputId": "6e3371cd-d294-4be7-a868-2eae5ee6e5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first={\n",
      "  movie: ChatPromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, template='{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.'), additional_kwargs={})])\n",
      "         | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000016B09907500>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000016B09959D90>, root_client=<openai.OpenAI object at 0x0000016B09904D70>, root_async_client=<openai.AsyncOpenAI object at 0x0000016B09907650>, model_name='moonshotai/kimi-k2-instruct-0905', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "         | StrOutputParser()\n",
      "} middle=[ChatPromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, template='{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요'), additional_kwargs={})]), ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000016B09907500>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000016B09959D90>, root_client=<openai.OpenAI object at 0x0000016B09904D70>, root_async_client=<openai.AsyncOpenAI object at 0x0000016B09907650>, model_name='moonshotai/kimi-k2-instruct-0905', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n",
      "\n",
      "🔹 영화 줄거리 요약:\n",
      " **쇼생크 탈출**\n",
      "\n",
      "제목: 쇼생크 탈출 (The Shawshank Redemption)  \n",
      "감독: 프랭크 다라본트  \n",
      "캐스팅: 팀 로빈스(앤이 듀프레인), 모건 프리먼(엘리스 보이드 ‘렐’ 레딩), 밥 건턴(워든 사무엘 노튼)  \n",
      "줄거리: 1947년, 은행 부지점장 앤디는 아내와 그녀의 정부를 살해한 누명을 쓴 채 두 번의 무기징역을 선고받고 쇼생크 교도소에 수감된다. 차분하고 지적인 그는 형무소 안에서도 희망을 잃지 않으며, 19년간의漫長한 세월 동안 벗이 된 재소자 ‘렐’과 함께 자유와 존엄의 진정한 의미를 깨닫는다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(chain2)\n",
    "\n",
    "# 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\\n\", response) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb684fd",
   "metadata": {},
   "source": [
    "##### chain1과 chain2에서 영화 제목이 일관되게 전달 되도록 변경 ( 잘 동작하는 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e30883ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 영화 줄거리 요약:\n",
      "('쇼생크 탈출\\n'\n",
      " '\\n'\n",
      " '쇼생크 탈출  \\n'\n",
      " '감독: 프랭크 다라본트  \\n'\n",
      " '출연: 팀 로빈스(앤디 듀프레인), 모건 프리먼(레드)  \\n'\n",
      " '줄거리: 누명으로 살인형을 선고 받은 은행원 앤디가 쇼생크 교도소에 수감되면서, 절망적인 현실 속에서도 희망과 자유를 향한 끈기를 잃지 '\n",
      " '않는다. 그는 동료 죄수 레드와 특별한 우정을 맺고, 19년간의 교도소 생활 끝에 자유를 쟁취하는 놀라운 탈출을 감행한다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: \"Drama\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\")\n",
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
